{"ast":null,"code":"import Sentiment from 'sentiment';\n// Simple sentence tokenizer\nfunction tokenizeSentences(text) {\n  return text.split(/[.!?]+/).map(s => s.trim()).filter(s => s.length > 10);\n}\n\n// Calculate cosine similarity between two sentences\nfunction cosineSimilarity(sent1, sent2) {\n  const words1 = sent1.toLowerCase().split(/\\s+/);\n  const words2 = sent2.toLowerCase().split(/\\s+/);\n  const allWords = Array.from(new Set([...words1, ...words2]));\n  const vector1 = allWords.map(word => words1.filter(w => w === word).length);\n  const vector2 = allWords.map(word => words2.filter(w => w === word).length);\n  const dotProduct = vector1.reduce((sum, val, i) => sum + val * vector2[i], 0);\n  const magnitude1 = Math.sqrt(vector1.reduce((sum, val) => sum + val * val, 0));\n  const magnitude2 = Math.sqrt(vector2.reduce((sum, val) => sum + val * val, 0));\n  return magnitude1 && magnitude2 ? dotProduct / (magnitude1 * magnitude2) : 0;\n}\n\n// Initialize sentiment analyzer\nconst sentiment = new Sentiment();\n\n// Calculate quality metrics for a summary\nfunction calculateQualityMetrics(originalText, summaryText, selectedSentences, allSentences) {\n  // Coverage: ratio of unique words in summary vs original\n  const originalWords = new Set(originalText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const summaryWords = new Set(summaryText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const coverage = summaryWords.size / originalWords.size;\n\n  // Coherence: average similarity between consecutive sentences in summary\n  let coherenceSum = 0;\n  for (let i = 0; i < selectedSentences.length - 1; i++) {\n    coherenceSum += cosineSimilarity(selectedSentences[i], selectedSentences[i + 1]);\n  }\n  const coherence = selectedSentences.length > 1 ? coherenceSum / (selectedSentences.length - 1) : 1;\n\n  // Diversity: ratio of unique words to total words in summary\n  const totalSummaryWords = summaryText.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const diversity = summaryWords.size / totalSummaryWords.length;\n\n  // Confidence: weighted combination of metrics\n  const confidence = coverage * 0.4 + coherence * 0.3 + diversity * 0.3;\n\n  // Sentiment analysis\n  const sentimentResult = sentiment.analyze(summaryText);\n  return {\n    coverage: Math.round(coverage * 100) / 100,\n    coherence: Math.round(coherence * 100) / 100,\n    diversity: Math.round(diversity * 100) / 100,\n    confidence: Math.round(confidence * 100) / 100,\n    sentiment: {\n      score: sentimentResult.score,\n      comparative: Math.round(sentimentResult.comparative * 100) / 100,\n      positive: sentimentResult.positive,\n      negative: sentimentResult.negative\n    }\n  };\n}\n\n// Generate visualization data\nfunction generateVisualizationData(sentences, scores, similarityMatrix) {\n  // Limit visualization to top 25 sentences to improve performance\n  const MAX_NODES = 25;\n\n  // Get indices of top scoring sentences\n  const rankedIndices = sentences.map((_, index) => ({\n    index,\n    score: scores[index] || 0\n  })).sort((a, b) => b.score - a.score).slice(0, Math.min(MAX_NODES, sentences.length)).map(item => item.index);\n\n  // Create sentence nodes for graph visualization (only for top sentences)\n  const sentenceGraph = rankedIndices.map(originalIndex => {\n    const sentence = sentences[originalIndex];\n    const sentimentScore = sentiment.analyze(sentence).comparative;\n\n    // Only create connections to other top sentences\n    const connections = rankedIndices.map(targetIndex => {\n      var _similarityMatrix$ori;\n      return {\n        target: `sentence-${targetIndex}`,\n        weight: ((_similarityMatrix$ori = similarityMatrix[originalIndex]) === null || _similarityMatrix$ori === void 0 ? void 0 : _similarityMatrix$ori[targetIndex]) || 0\n      };\n    }).filter(conn => conn.weight > 0.1 && conn.target !== `sentence-${originalIndex}`);\n    return {\n      id: `sentence-${originalIndex}`,\n      text: sentence.slice(0, 100) + (sentence.length > 100 ? '...' : ''),\n      score: scores[originalIndex] || 0,\n      sentiment: sentimentScore,\n      connections\n    };\n  });\n\n  // Simple topic clustering based on word overlap\n  const topicClusters = generateTopicClusters(sentences);\n  return {\n    sentenceGraph,\n    topicClusters\n  };\n}\n\n// Generate topic clusters using simple k-means-like approach\nfunction generateTopicClusters(sentences) {\n  const words = sentences.flatMap(s => s.toLowerCase().match(/\\b\\w{4,}\\b/g) || []);\n  const wordFreq = {};\n  words.forEach(word => {\n    wordFreq[word] = (wordFreq[word] || 0) + 1;\n  });\n\n  // Get top keywords\n  const topWords = Object.entries(wordFreq).sort(([, a], [, b]) => b - a).slice(0, 12).map(([word]) => word);\n\n  // Create clusters based on keyword presence\n  const clusters = [];\n  const colors = ['#3B82F6', '#EF4444', '#10B981', '#F59E0B'];\n  for (let i = 0; i < Math.min(3, Math.ceil(topWords.length / 4)); i++) {\n    const clusterKeywords = topWords.slice(i * 4, (i + 1) * 4);\n    const clusterSentences = sentences.filter(sentence => clusterKeywords.some(keyword => sentence.toLowerCase().includes(keyword)));\n    if (clusterSentences.length > 0) {\n      clusters.push({\n        id: `cluster-${i}`,\n        keywords: clusterKeywords,\n        sentences: clusterSentences.map(s => s.slice(0, 80) + '...'),\n        centroid: [Math.random() * 100, Math.random() * 100],\n        // Simplified\n        color: colors[i % colors.length]\n      });\n    }\n  }\n  return clusters;\n}\n\n// TextRank implementation\nexport function textRankSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'TextRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Build similarity matrix\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      if (i === j) {\n        similarityMatrix[i][j] = 0;\n      } else {\n        similarityMatrix[i][j] = cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n  }\n\n  // PageRank algorithm\n  const scores = new Array(sentences.length).fill(1);\n  const damping = 0.85;\n  const iterations = 50;\n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = [...scores];\n    for (let i = 0; i < sentences.length; i++) {\n      let sum = 0;\n      for (let j = 0; j < sentences.length; j++) {\n        if (i !== j) {\n          const totalSim = similarityMatrix[j].reduce((a, b) => a + b, 0);\n          if (totalSim > 0) {\n            sum += similarityMatrix[j][i] / totalSim * scores[j];\n          }\n        }\n      }\n      newScores[i] = 1 - damping + damping * sum;\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: scores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  return {\n    method: 'TextRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// LexRank implementation\nexport function lexRankSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'LexRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Build similarity matrix\n  const threshold = 0.1;\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      const similarity = cosineSimilarity(sentences[i], sentences[j]);\n      similarityMatrix[i][j] = similarity > threshold ? similarity : 0;\n    }\n  }\n\n  // Normalize rows\n  for (let i = 0; i < sentences.length; i++) {\n    const rowSum = similarityMatrix[i].reduce((a, b) => a + b, 0);\n    if (rowSum > 0) {\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] /= rowSum;\n      }\n    }\n  }\n\n  // Power iteration\n  const scores = new Array(sentences.length).fill(1 / sentences.length);\n  const iterations = 50;\n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = new Array(sentences.length).fill(0);\n    for (let i = 0; i < sentences.length; i++) {\n      for (let j = 0; j < sentences.length; j++) {\n        newScores[i] += similarityMatrix[j][i] * scores[j];\n      }\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: scores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  return {\n    method: 'LexRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// BART-based abstractive summarization using Hugging Face API\nexport async function bartSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  try {\n    var _result$;\n    // Use Hugging Face's free inference API for BART\n    const response = await fetch('https://api-inference.huggingface.co/models/facebook/bart-large-cnn', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        inputs: text.slice(0, 1024),\n        // Limit input size for API\n        parameters: {\n          max_length: Math.min(150, numSentences * 50),\n          min_length: Math.min(50, numSentences * 15),\n          do_sample: false\n        }\n      })\n    });\n    if (!response.ok) {\n      throw new Error(`BART API error: ${response.status}`);\n    }\n    const result = await response.json();\n    let summary = ((_result$ = result[0]) === null || _result$ === void 0 ? void 0 : _result$.summary_text) || text.slice(0, 200) + '...';\n\n    // Split BART summary into sentences for consistency with other methods\n    const summarySentences = tokenizeSentences(summary);\n\n    // Calculate quality metrics\n    const qualityMetrics = calculateQualityMetrics(text, summary, summarySentences, sentences);\n\n    // Create sentence scores based on similarity to summary\n    const sentenceScores = sentences.map(sentence => {\n      return cosineSimilarity(sentence, summary);\n    });\n\n    // Create a similarity matrix for visualization\n    const similarityMatrix = [];\n    for (let i = 0; i < sentences.length; i++) {\n      similarityMatrix[i] = [];\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n\n    // Generate visualization data\n    const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n    return {\n      method: 'BART',\n      summary,\n      sentences: summarySentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  } catch (error) {\n    console.error('BART summarization failed:', error);\n\n    // Fallback to simple extractive summarization\n    const words = text.toLowerCase().match(/\\b\\w+\\b/g) || [];\n    const wordFreq = {};\n    words.forEach(word => {\n      if (word.length > 3) {\n        wordFreq[word] = (wordFreq[word] || 0) + 1;\n      }\n    });\n    const sentenceScores = sentences.map(sentence => {\n      const sentenceWords = sentence.toLowerCase().match(/\\b\\w+\\b/g) || [];\n      const score = sentenceWords.reduce((sum, word) => sum + (wordFreq[word] || 0), 0);\n      return score / sentenceWords.length;\n    });\n    const rankedSentences = sentences.map((sentence, index) => ({\n      sentence,\n      score: sentenceScores[index],\n      index\n    })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n    const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n    const selectedSentences = rankedSentences.map(item => item.sentence);\n    const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n    const similarityMatrix = [];\n    for (let i = 0; i < sentences.length; i++) {\n      similarityMatrix[i] = [];\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n    const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n    return {\n      method: 'BART (Fallback)',\n      summary,\n      sentences: selectedSentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n}","map":{"version":3,"names":["Sentiment","tokenizeSentences","text","split","map","s","trim","filter","length","cosineSimilarity","sent1","sent2","words1","toLowerCase","words2","allWords","Array","from","Set","vector1","word","w","vector2","dotProduct","reduce","sum","val","i","magnitude1","Math","sqrt","magnitude2","sentiment","calculateQualityMetrics","originalText","summaryText","selectedSentences","allSentences","originalWords","match","summaryWords","coverage","size","coherenceSum","coherence","totalSummaryWords","diversity","confidence","sentimentResult","analyze","round","score","comparative","positive","negative","generateVisualizationData","sentences","scores","similarityMatrix","MAX_NODES","rankedIndices","_","index","sort","a","b","slice","min","item","sentenceGraph","originalIndex","sentence","sentimentScore","connections","targetIndex","_similarityMatrix$ori","target","weight","conn","id","topicClusters","generateTopicClusters","words","flatMap","wordFreq","forEach","topWords","Object","entries","clusters","colors","ceil","clusterKeywords","clusterSentences","some","keyword","includes","push","keywords","centroid","random","color","textRankSummarize","numSentences","startTime","Date","now","summary","join","qualityMetrics","visualizationData","method","processingTime","j","fill","damping","iterations","iter","newScores","totalSim","splice","rankedSentences","lexRankSummarize","threshold","similarity","rowSum","bartSummarize","_result$","response","fetch","headers","body","JSON","stringify","inputs","parameters","max_length","min_length","do_sample","ok","Error","status","result","json","summary_text","summarySentences","sentenceScores","error","console","sentenceWords"],"sources":["/Users/averyreyna/Codebases/rerank/src/utils/textSummarization.ts"],"sourcesContent":["import Sentiment from 'sentiment';\n\nexport interface QualityMetrics {\n  coverage: number;\n  coherence: number;\n  diversity: number;\n  confidence: number;\n  sentiment: {\n    score: number;\n    comparative: number;\n    positive: string[];\n    negative: string[];\n  };\n}\n\nexport interface SentenceNode {\n  id: string;\n  text: string;\n  score: number;\n  sentiment: number;\n  connections: { target: string; weight: number }[];\n  position?: { x: number; y: number };\n}\n\nexport interface TopicCluster {\n  id: string;\n  keywords: string[];\n  sentences: string[];\n  centroid: number[];\n  color: string;\n}\n\nexport interface SummaryResult {\n  method: string;\n  summary: string;\n  sentences: string[];\n  processingTime: number;\n  qualityMetrics: QualityMetrics;\n  visualizationData: {\n    sentenceGraph: SentenceNode[];\n    topicClusters: TopicCluster[];\n  };\n}\n\n// Simple sentence tokenizer\nfunction tokenizeSentences(text: string): string[] {\n  return text\n    .split(/[.!?]+/)\n    .map(s => s.trim())\n    .filter(s => s.length > 10);\n}\n\n// Calculate cosine similarity between two sentences\nfunction cosineSimilarity(sent1: string, sent2: string): number {\n  const words1 = sent1.toLowerCase().split(/\\s+/);\n  const words2 = sent2.toLowerCase().split(/\\s+/);\n  \n  const allWords = Array.from(new Set([...words1, ...words2]));\n  \n  const vector1 = allWords.map(word => words1.filter(w => w === word).length);\n  const vector2 = allWords.map(word => words2.filter(w => w === word).length);\n  \n  const dotProduct = vector1.reduce((sum, val, i) => sum + val * vector2[i], 0);\n  const magnitude1 = Math.sqrt(vector1.reduce((sum, val) => sum + val * val, 0));\n  const magnitude2 = Math.sqrt(vector2.reduce((sum, val) => sum + val * val, 0));\n  \n  return magnitude1 && magnitude2 ? dotProduct / (magnitude1 * magnitude2) : 0;\n}\n\n// Initialize sentiment analyzer\nconst sentiment = new Sentiment();\n\n// Calculate quality metrics for a summary\nfunction calculateQualityMetrics(\n  originalText: string, \n  summaryText: string, \n  selectedSentences: string[],\n  allSentences: string[]\n): QualityMetrics {\n  // Coverage: ratio of unique words in summary vs original\n  const originalWords = new Set(originalText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const summaryWords = new Set(summaryText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const coverage = summaryWords.size / originalWords.size;\n\n  // Coherence: average similarity between consecutive sentences in summary\n  let coherenceSum = 0;\n  for (let i = 0; i < selectedSentences.length - 1; i++) {\n    coherenceSum += cosineSimilarity(selectedSentences[i], selectedSentences[i + 1]);\n  }\n  const coherence = selectedSentences.length > 1 ? coherenceSum / (selectedSentences.length - 1) : 1;\n\n  // Diversity: ratio of unique words to total words in summary\n  const totalSummaryWords = summaryText.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const diversity = summaryWords.size / totalSummaryWords.length;\n\n  // Confidence: weighted combination of metrics\n  const confidence = (coverage * 0.4 + coherence * 0.3 + diversity * 0.3);\n\n  // Sentiment analysis\n  const sentimentResult = sentiment.analyze(summaryText);\n\n  return {\n    coverage: Math.round(coverage * 100) / 100,\n    coherence: Math.round(coherence * 100) / 100,\n    diversity: Math.round(diversity * 100) / 100,\n    confidence: Math.round(confidence * 100) / 100,\n    sentiment: {\n      score: sentimentResult.score,\n      comparative: Math.round(sentimentResult.comparative * 100) / 100,\n      positive: sentimentResult.positive,\n      negative: sentimentResult.negative\n    }\n  };\n}\n\n// Generate visualization data\nfunction generateVisualizationData(\n  sentences: string[], \n  scores: number[], \n  similarityMatrix: number[][]\n): { sentenceGraph: SentenceNode[]; topicClusters: TopicCluster[] } {\n  // Limit visualization to top 25 sentences to improve performance\n  const MAX_NODES = 25;\n  \n  // Get indices of top scoring sentences\n  const rankedIndices = sentences\n    .map((_, index) => ({ index, score: scores[index] || 0 }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, Math.min(MAX_NODES, sentences.length))\n    .map(item => item.index);\n\n  // Create sentence nodes for graph visualization (only for top sentences)\n  const sentenceGraph: SentenceNode[] = rankedIndices.map((originalIndex) => {\n    const sentence = sentences[originalIndex];\n    const sentimentScore = sentiment.analyze(sentence).comparative;\n    \n    // Only create connections to other top sentences\n    const connections = rankedIndices.map((targetIndex) => ({\n      target: `sentence-${targetIndex}`,\n      weight: similarityMatrix[originalIndex]?.[targetIndex] || 0\n    })).filter(conn => conn.weight > 0.1 && conn.target !== `sentence-${originalIndex}`);\n\n    return {\n      id: `sentence-${originalIndex}`,\n      text: sentence.slice(0, 100) + (sentence.length > 100 ? '...' : ''),\n      score: scores[originalIndex] || 0,\n      sentiment: sentimentScore,\n      connections\n    };\n  });\n\n  // Simple topic clustering based on word overlap\n  const topicClusters = generateTopicClusters(sentences);\n\n  return { sentenceGraph, topicClusters };\n}\n\n// Generate topic clusters using simple k-means-like approach\nfunction generateTopicClusters(sentences: string[]): TopicCluster[] {\n  const words = sentences.flatMap(s => \n    s.toLowerCase().match(/\\b\\w{4,}\\b/g) || []\n  );\n  \n  const wordFreq: { [key: string]: number } = {};\n  words.forEach(word => {\n    wordFreq[word] = (wordFreq[word] || 0) + 1;\n  });\n\n  // Get top keywords\n  const topWords = Object.entries(wordFreq)\n    .sort(([,a], [,b]) => b - a)\n    .slice(0, 12)\n    .map(([word]) => word);\n\n  // Create clusters based on keyword presence\n  const clusters: TopicCluster[] = [];\n  const colors = ['#3B82F6', '#EF4444', '#10B981', '#F59E0B'];\n  \n  for (let i = 0; i < Math.min(3, Math.ceil(topWords.length / 4)); i++) {\n    const clusterKeywords = topWords.slice(i * 4, (i + 1) * 4);\n    const clusterSentences = sentences.filter(sentence => \n      clusterKeywords.some(keyword => \n        sentence.toLowerCase().includes(keyword)\n      )\n    );\n\n    if (clusterSentences.length > 0) {\n      clusters.push({\n        id: `cluster-${i}`,\n        keywords: clusterKeywords,\n        sentences: clusterSentences.map(s => s.slice(0, 80) + '...'),\n        centroid: [Math.random() * 100, Math.random() * 100], // Simplified\n        color: colors[i % colors.length]\n      });\n    }\n  }\n\n  return clusters;\n}\n\n// TextRank implementation\nexport function textRankSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'TextRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Build similarity matrix\n  const similarityMatrix: number[][] = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      if (i === j) {\n        similarityMatrix[i][j] = 0;\n      } else {\n        similarityMatrix[i][j] = cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n  }\n  \n  // PageRank algorithm\n  const scores = new Array(sentences.length).fill(1);\n  const damping = 0.85;\n  const iterations = 50;\n  \n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = [...scores];\n    for (let i = 0; i < sentences.length; i++) {\n      let sum = 0;\n      for (let j = 0; j < sentences.length; j++) {\n        if (i !== j) {\n          const totalSim = similarityMatrix[j].reduce((a, b) => a + b, 0);\n          if (totalSim > 0) {\n            sum += (similarityMatrix[j][i] / totalSim) * scores[j];\n          }\n        }\n      }\n      newScores[i] = (1 - damping) + damping * sum;\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: scores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  \n  return {\n    method: 'TextRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// LexRank implementation\nexport function lexRankSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'LexRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Build similarity matrix\n  const threshold = 0.1;\n  const similarityMatrix: number[][] = [];\n  \n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      const similarity = cosineSimilarity(sentences[i], sentences[j]);\n      similarityMatrix[i][j] = similarity > threshold ? similarity : 0;\n    }\n  }\n  \n  // Normalize rows\n  for (let i = 0; i < sentences.length; i++) {\n    const rowSum = similarityMatrix[i].reduce((a, b) => a + b, 0);\n    if (rowSum > 0) {\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] /= rowSum;\n      }\n    }\n  }\n  \n  // Power iteration\n  const scores = new Array(sentences.length).fill(1 / sentences.length);\n  const iterations = 50;\n  \n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = new Array(sentences.length).fill(0);\n    for (let i = 0; i < sentences.length; i++) {\n      for (let j = 0; j < sentences.length; j++) {\n        newScores[i] += similarityMatrix[j][i] * scores[j];\n      }\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: scores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  \n  return {\n    method: 'LexRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// BART-based abstractive summarization using Hugging Face API\nexport async function bartSummarize(text: string, numSentences: number = 3): Promise<SummaryResult> {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  try {\n    // Use Hugging Face's free inference API for BART\n    const response = await fetch('https://api-inference.huggingface.co/models/facebook/bart-large-cnn', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        inputs: text.slice(0, 1024), // Limit input size for API\n        parameters: {\n          max_length: Math.min(150, numSentences * 50),\n          min_length: Math.min(50, numSentences * 15),\n          do_sample: false\n        }\n      })\n    });\n\n    if (!response.ok) {\n      throw new Error(`BART API error: ${response.status}`);\n    }\n\n    const result = await response.json();\n    let summary = result[0]?.summary_text || text.slice(0, 200) + '...';\n    \n    // Split BART summary into sentences for consistency with other methods\n    const summarySentences = tokenizeSentences(summary);\n    \n    // Calculate quality metrics\n    const qualityMetrics = calculateQualityMetrics(text, summary, summarySentences, sentences);\n    \n    // Create sentence scores based on similarity to summary\n    const sentenceScores: number[] = sentences.map((sentence: string) => {\n      return cosineSimilarity(sentence, summary);\n    });\n    \n    // Create a similarity matrix for visualization\n    const similarityMatrix: number[][] = [];\n    for (let i = 0; i < sentences.length; i++) {\n      similarityMatrix[i] = [];\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n    \n    // Generate visualization data\n    const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n    \n    return {\n      method: 'BART',\n      summary,\n      sentences: summarySentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n    \n  } catch (error) {\n    console.error('BART summarization failed:', error);\n    \n    // Fallback to simple extractive summarization\n    const words = text.toLowerCase().match(/\\b\\w+\\b/g) || [];\n    const wordFreq: { [key: string]: number } = {};\n    \n    words.forEach((word: string) => {\n      if (word.length > 3) {\n        wordFreq[word] = (wordFreq[word] || 0) + 1;\n      }\n    });\n    \n    const sentenceScores: number[] = sentences.map((sentence: string) => {\n      const sentenceWords: string[] = sentence.toLowerCase().match(/\\b\\w+\\b/g) || [];\n      const score: number = sentenceWords.reduce((sum: number, word: string) => sum + (wordFreq[word] || 0), 0);\n      return score / sentenceWords.length;\n    });\n    \n    const rankedSentences = sentences\n      .map((sentence, index) => ({ sentence, score: sentenceScores[index], index }))\n      .sort((a, b) => b.score - a.score)\n      .slice(0, numSentences)\n      .sort((a, b) => a.index - b.index);\n    \n    const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n    const selectedSentences = rankedSentences.map(item => item.sentence);\n    const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n    \n    const similarityMatrix: number[][] = [];\n    for (let i = 0; i < sentences.length; i++) {\n      similarityMatrix[i] = [];\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n    \n    const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n    \n    return {\n      method: 'BART (Fallback)',\n      summary,\n      sentences: selectedSentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n}\n"],"mappings":"AAAA,OAAOA,SAAS,MAAM,WAAW;AA4CjC;AACA,SAASC,iBAAiBA,CAACC,IAAY,EAAY;EACjD,OAAOA,IAAI,CACRC,KAAK,CAAC,QAAQ,CAAC,CACfC,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACC,IAAI,CAAC,CAAC,CAAC,CAClBC,MAAM,CAACF,CAAC,IAAIA,CAAC,CAACG,MAAM,GAAG,EAAE,CAAC;AAC/B;;AAEA;AACA,SAASC,gBAAgBA,CAACC,KAAa,EAAEC,KAAa,EAAU;EAC9D,MAAMC,MAAM,GAAGF,KAAK,CAACG,WAAW,CAAC,CAAC,CAACV,KAAK,CAAC,KAAK,CAAC;EAC/C,MAAMW,MAAM,GAAGH,KAAK,CAACE,WAAW,CAAC,CAAC,CAACV,KAAK,CAAC,KAAK,CAAC;EAE/C,MAAMY,QAAQ,GAAGC,KAAK,CAACC,IAAI,CAAC,IAAIC,GAAG,CAAC,CAAC,GAAGN,MAAM,EAAE,GAAGE,MAAM,CAAC,CAAC,CAAC;EAE5D,MAAMK,OAAO,GAAGJ,QAAQ,CAACX,GAAG,CAACgB,IAAI,IAAIR,MAAM,CAACL,MAAM,CAACc,CAAC,IAAIA,CAAC,KAAKD,IAAI,CAAC,CAACZ,MAAM,CAAC;EAC3E,MAAMc,OAAO,GAAGP,QAAQ,CAACX,GAAG,CAACgB,IAAI,IAAIN,MAAM,CAACP,MAAM,CAACc,CAAC,IAAIA,CAAC,KAAKD,IAAI,CAAC,CAACZ,MAAM,CAAC;EAE3E,MAAMe,UAAU,GAAGJ,OAAO,CAACK,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,EAAEC,CAAC,KAAKF,GAAG,GAAGC,GAAG,GAAGJ,OAAO,CAACK,CAAC,CAAC,EAAE,CAAC,CAAC;EAC7E,MAAMC,UAAU,GAAGC,IAAI,CAACC,IAAI,CAACX,OAAO,CAACK,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAGC,GAAG,GAAGA,GAAG,EAAE,CAAC,CAAC,CAAC;EAC9E,MAAMK,UAAU,GAAGF,IAAI,CAACC,IAAI,CAACR,OAAO,CAACE,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAGC,GAAG,GAAGA,GAAG,EAAE,CAAC,CAAC,CAAC;EAE9E,OAAOE,UAAU,IAAIG,UAAU,GAAGR,UAAU,IAAIK,UAAU,GAAGG,UAAU,CAAC,GAAG,CAAC;AAC9E;;AAEA;AACA,MAAMC,SAAS,GAAG,IAAIhC,SAAS,CAAC,CAAC;;AAEjC;AACA,SAASiC,uBAAuBA,CAC9BC,YAAoB,EACpBC,WAAmB,EACnBC,iBAA2B,EAC3BC,YAAsB,EACN;EAChB;EACA,MAAMC,aAAa,GAAG,IAAIpB,GAAG,CAACgB,YAAY,CAACrB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC;EACjF,MAAMC,YAAY,GAAG,IAAItB,GAAG,CAACiB,WAAW,CAACtB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC;EAC/E,MAAME,QAAQ,GAAGD,YAAY,CAACE,IAAI,GAAGJ,aAAa,CAACI,IAAI;;EAEvD;EACA,IAAIC,YAAY,GAAG,CAAC;EACpB,KAAK,IAAIhB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGS,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,EAAEmB,CAAC,EAAE,EAAE;IACrDgB,YAAY,IAAIlC,gBAAgB,CAAC2B,iBAAiB,CAACT,CAAC,CAAC,EAAES,iBAAiB,CAACT,CAAC,GAAG,CAAC,CAAC,CAAC;EAClF;EACA,MAAMiB,SAAS,GAAGR,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,GAAGmC,YAAY,IAAIP,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC;;EAElG;EACA,MAAMqC,iBAAiB,GAAGV,WAAW,CAACtB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;EAC3E,MAAMO,SAAS,GAAGN,YAAY,CAACE,IAAI,GAAGG,iBAAiB,CAACrC,MAAM;;EAE9D;EACA,MAAMuC,UAAU,GAAIN,QAAQ,GAAG,GAAG,GAAGG,SAAS,GAAG,GAAG,GAAGE,SAAS,GAAG,GAAI;;EAEvE;EACA,MAAME,eAAe,GAAGhB,SAAS,CAACiB,OAAO,CAACd,WAAW,CAAC;EAEtD,OAAO;IACLM,QAAQ,EAAEZ,IAAI,CAACqB,KAAK,CAACT,QAAQ,GAAG,GAAG,CAAC,GAAG,GAAG;IAC1CG,SAAS,EAAEf,IAAI,CAACqB,KAAK,CAACN,SAAS,GAAG,GAAG,CAAC,GAAG,GAAG;IAC5CE,SAAS,EAAEjB,IAAI,CAACqB,KAAK,CAACJ,SAAS,GAAG,GAAG,CAAC,GAAG,GAAG;IAC5CC,UAAU,EAAElB,IAAI,CAACqB,KAAK,CAACH,UAAU,GAAG,GAAG,CAAC,GAAG,GAAG;IAC9Cf,SAAS,EAAE;MACTmB,KAAK,EAAEH,eAAe,CAACG,KAAK;MAC5BC,WAAW,EAAEvB,IAAI,CAACqB,KAAK,CAACF,eAAe,CAACI,WAAW,GAAG,GAAG,CAAC,GAAG,GAAG;MAChEC,QAAQ,EAAEL,eAAe,CAACK,QAAQ;MAClCC,QAAQ,EAAEN,eAAe,CAACM;IAC5B;EACF,CAAC;AACH;;AAEA;AACA,SAASC,yBAAyBA,CAChCC,SAAmB,EACnBC,MAAgB,EAChBC,gBAA4B,EACsC;EAClE;EACA,MAAMC,SAAS,GAAG,EAAE;;EAEpB;EACA,MAAMC,aAAa,GAAGJ,SAAS,CAC5BpD,GAAG,CAAC,CAACyD,CAAC,EAAEC,KAAK,MAAM;IAAEA,KAAK;IAAEX,KAAK,EAAEM,MAAM,CAACK,KAAK,CAAC,IAAI;EAAE,CAAC,CAAC,CAAC,CACzDC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAErC,IAAI,CAACsC,GAAG,CAACR,SAAS,EAAEH,SAAS,CAAChD,MAAM,CAAC,CAAC,CAC/CJ,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACN,KAAK,CAAC;;EAE1B;EACA,MAAMO,aAA6B,GAAGT,aAAa,CAACxD,GAAG,CAAEkE,aAAa,IAAK;IACzE,MAAMC,QAAQ,GAAGf,SAAS,CAACc,aAAa,CAAC;IACzC,MAAME,cAAc,GAAGxC,SAAS,CAACiB,OAAO,CAACsB,QAAQ,CAAC,CAACnB,WAAW;;IAE9D;IACA,MAAMqB,WAAW,GAAGb,aAAa,CAACxD,GAAG,CAAEsE,WAAW;MAAA,IAAAC,qBAAA;MAAA,OAAM;QACtDC,MAAM,EAAE,YAAYF,WAAW,EAAE;QACjCG,MAAM,EAAE,EAAAF,qBAAA,GAAAjB,gBAAgB,CAACY,aAAa,CAAC,cAAAK,qBAAA,uBAA/BA,qBAAA,CAAkCD,WAAW,CAAC,KAAI;MAC5D,CAAC;IAAA,CAAC,CAAC,CAACnE,MAAM,CAACuE,IAAI,IAAIA,IAAI,CAACD,MAAM,GAAG,GAAG,IAAIC,IAAI,CAACF,MAAM,KAAK,YAAYN,aAAa,EAAE,CAAC;IAEpF,OAAO;MACLS,EAAE,EAAE,YAAYT,aAAa,EAAE;MAC/BpE,IAAI,EAAEqE,QAAQ,CAACL,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,IAAIK,QAAQ,CAAC/D,MAAM,GAAG,GAAG,GAAG,KAAK,GAAG,EAAE,CAAC;MACnE2C,KAAK,EAAEM,MAAM,CAACa,aAAa,CAAC,IAAI,CAAC;MACjCtC,SAAS,EAAEwC,cAAc;MACzBC;IACF,CAAC;EACH,CAAC,CAAC;;EAEF;EACA,MAAMO,aAAa,GAAGC,qBAAqB,CAACzB,SAAS,CAAC;EAEtD,OAAO;IAAEa,aAAa;IAAEW;EAAc,CAAC;AACzC;;AAEA;AACA,SAASC,qBAAqBA,CAACzB,SAAmB,EAAkB;EAClE,MAAM0B,KAAK,GAAG1B,SAAS,CAAC2B,OAAO,CAAC9E,CAAC,IAC/BA,CAAC,CAACQ,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,aAAa,CAAC,IAAI,EAC1C,CAAC;EAED,MAAM6C,QAAmC,GAAG,CAAC,CAAC;EAC9CF,KAAK,CAACG,OAAO,CAACjE,IAAI,IAAI;IACpBgE,QAAQ,CAAChE,IAAI,CAAC,GAAG,CAACgE,QAAQ,CAAChE,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;EAC5C,CAAC,CAAC;;EAEF;EACA,MAAMkE,QAAQ,GAAGC,MAAM,CAACC,OAAO,CAACJ,QAAQ,CAAC,CACtCrB,IAAI,CAAC,CAAC,GAAEC,CAAC,CAAC,EAAE,GAAEC,CAAC,CAAC,KAAKA,CAAC,GAAGD,CAAC,CAAC,CAC3BE,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,CACZ9D,GAAG,CAAC,CAAC,CAACgB,IAAI,CAAC,KAAKA,IAAI,CAAC;;EAExB;EACA,MAAMqE,QAAwB,GAAG,EAAE;EACnC,MAAMC,MAAM,GAAG,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;EAE3D,KAAK,IAAI/D,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGE,IAAI,CAACsC,GAAG,CAAC,CAAC,EAAEtC,IAAI,CAAC8D,IAAI,CAACL,QAAQ,CAAC9E,MAAM,GAAG,CAAC,CAAC,CAAC,EAAEmB,CAAC,EAAE,EAAE;IACpE,MAAMiE,eAAe,GAAGN,QAAQ,CAACpB,KAAK,CAACvC,CAAC,GAAG,CAAC,EAAE,CAACA,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IAC1D,MAAMkE,gBAAgB,GAAGrC,SAAS,CAACjD,MAAM,CAACgE,QAAQ,IAChDqB,eAAe,CAACE,IAAI,CAACC,OAAO,IAC1BxB,QAAQ,CAAC1D,WAAW,CAAC,CAAC,CAACmF,QAAQ,CAACD,OAAO,CACzC,CACF,CAAC;IAED,IAAIF,gBAAgB,CAACrF,MAAM,GAAG,CAAC,EAAE;MAC/BiF,QAAQ,CAACQ,IAAI,CAAC;QACZlB,EAAE,EAAE,WAAWpD,CAAC,EAAE;QAClBuE,QAAQ,EAAEN,eAAe;QACzBpC,SAAS,EAAEqC,gBAAgB,CAACzF,GAAG,CAACC,CAAC,IAAIA,CAAC,CAAC6D,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,GAAG,KAAK,CAAC;QAC5DiC,QAAQ,EAAE,CAACtE,IAAI,CAACuE,MAAM,CAAC,CAAC,GAAG,GAAG,EAAEvE,IAAI,CAACuE,MAAM,CAAC,CAAC,GAAG,GAAG,CAAC;QAAE;QACtDC,KAAK,EAAEX,MAAM,CAAC/D,CAAC,GAAG+D,MAAM,CAAClF,MAAM;MACjC,CAAC,CAAC;IACJ;EACF;EAEA,OAAOiF,QAAQ;AACjB;;AAEA;AACA,OAAO,SAASa,iBAAiBA,CAACpG,IAAY,EAAEqG,YAAoB,GAAG,CAAC,EAAiB;EACvF,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAMlD,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAI+F,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAGnD,SAAS,CAACoD,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAG5E,uBAAuB,CAAC/B,IAAI,EAAEyG,OAAO,EAAEnD,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMsD,iBAAiB,GAAGvD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACL2G,MAAM,EAAE,UAAU;MAClBJ,OAAO;MACPnD,SAAS;MACTwD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAMpD,gBAA4B,GAAG,EAAE;EACvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIsF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzD,SAAS,CAAChD,MAAM,EAAEyG,CAAC,EAAE,EAAE;MACzC,IAAItF,CAAC,KAAKsF,CAAC,EAAE;QACXvD,gBAAgB,CAAC/B,CAAC,CAAC,CAACsF,CAAC,CAAC,GAAG,CAAC;MAC5B,CAAC,MAAM;QACLvD,gBAAgB,CAAC/B,CAAC,CAAC,CAACsF,CAAC,CAAC,GAAGxG,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACyD,CAAC,CAAC,CAAC;MACvE;IACF;EACF;;EAEA;EACA,MAAMxD,MAAM,GAAG,IAAIzC,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAAC0G,IAAI,CAAC,CAAC,CAAC;EAClD,MAAMC,OAAO,GAAG,IAAI;EACpB,MAAMC,UAAU,GAAG,EAAE;EAErB,KAAK,IAAIC,IAAI,GAAG,CAAC,EAAEA,IAAI,GAAGD,UAAU,EAAEC,IAAI,EAAE,EAAE;IAC5C,MAAMC,SAAS,GAAG,CAAC,GAAG7D,MAAM,CAAC;IAC7B,KAAK,IAAI9B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC,IAAIF,GAAG,GAAG,CAAC;MACX,KAAK,IAAIwF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzD,SAAS,CAAChD,MAAM,EAAEyG,CAAC,EAAE,EAAE;QACzC,IAAItF,CAAC,KAAKsF,CAAC,EAAE;UACX,MAAMM,QAAQ,GAAG7D,gBAAgB,CAACuD,CAAC,CAAC,CAACzF,MAAM,CAAC,CAACwC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC;UAC/D,IAAIsD,QAAQ,GAAG,CAAC,EAAE;YAChB9F,GAAG,IAAKiC,gBAAgB,CAACuD,CAAC,CAAC,CAACtF,CAAC,CAAC,GAAG4F,QAAQ,GAAI9D,MAAM,CAACwD,CAAC,CAAC;UACxD;QACF;MACF;MACAK,SAAS,CAAC3F,CAAC,CAAC,GAAI,CAAC,GAAGwF,OAAO,GAAIA,OAAO,GAAG1F,GAAG;IAC9C;IACAgC,MAAM,CAAC+D,MAAM,CAAC,CAAC,EAAE/D,MAAM,CAACjD,MAAM,EAAE,GAAG8G,SAAS,CAAC;EAC/C;;EAEA;EACA,MAAMG,eAAe,GAAGjE,SAAS,CAC9BpD,GAAG,CAAC,CAACmE,QAAQ,EAAET,KAAK,MAAM;IAAES,QAAQ;IAAEpB,KAAK,EAAEM,MAAM,CAACK,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CACrEC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAEqC,YAAY,CAAC,CACtBxC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACF,KAAK,GAAGG,CAAC,CAACH,KAAK,CAAC;EAEpC,MAAM6C,OAAO,GAAGc,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC,CAACqC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMxE,iBAAiB,GAAGqF,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC;;EAEpE;EACA,MAAMsC,cAAc,GAAG5E,uBAAuB,CAAC/B,IAAI,EAAEyG,OAAO,EAAEvE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAMsD,iBAAiB,GAAGvD,yBAAyB,CAACC,SAAS,EAAEC,MAAM,EAAEC,gBAAgB,CAAC;EAExF,OAAO;IACLqD,MAAM,EAAE,UAAU;IAClBJ,OAAO;IACPnD,SAAS,EAAEpB,iBAAiB;IAC5B4E,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH;;AAEA;AACA,OAAO,SAASY,gBAAgBA,CAACxH,IAAY,EAAEqG,YAAoB,GAAG,CAAC,EAAiB;EACtF,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAMlD,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAI+F,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAGnD,SAAS,CAACoD,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAG5E,uBAAuB,CAAC/B,IAAI,EAAEyG,OAAO,EAAEnD,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMsD,iBAAiB,GAAGvD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACL2G,MAAM,EAAE,SAAS;MACjBJ,OAAO;MACPnD,SAAS;MACTwD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAMa,SAAS,GAAG,GAAG;EACrB,MAAMjE,gBAA4B,GAAG,EAAE;EAEvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIsF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzD,SAAS,CAAChD,MAAM,EAAEyG,CAAC,EAAE,EAAE;MACzC,MAAMW,UAAU,GAAGnH,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACyD,CAAC,CAAC,CAAC;MAC/DvD,gBAAgB,CAAC/B,CAAC,CAAC,CAACsF,CAAC,CAAC,GAAGW,UAAU,GAAGD,SAAS,GAAGC,UAAU,GAAG,CAAC;IAClE;EACF;;EAEA;EACA,KAAK,IAAIjG,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC,MAAMkG,MAAM,GAAGnE,gBAAgB,CAAC/B,CAAC,CAAC,CAACH,MAAM,CAAC,CAACwC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC;IAC7D,IAAI4D,MAAM,GAAG,CAAC,EAAE;MACd,KAAK,IAAIZ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzD,SAAS,CAAChD,MAAM,EAAEyG,CAAC,EAAE,EAAE;QACzCvD,gBAAgB,CAAC/B,CAAC,CAAC,CAACsF,CAAC,CAAC,IAAIY,MAAM;MAClC;IACF;EACF;;EAEA;EACA,MAAMpE,MAAM,GAAG,IAAIzC,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAAC0G,IAAI,CAAC,CAAC,GAAG1D,SAAS,CAAChD,MAAM,CAAC;EACrE,MAAM4G,UAAU,GAAG,EAAE;EAErB,KAAK,IAAIC,IAAI,GAAG,CAAC,EAAEA,IAAI,GAAGD,UAAU,EAAEC,IAAI,EAAE,EAAE;IAC5C,MAAMC,SAAS,GAAG,IAAItG,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAAC0G,IAAI,CAAC,CAAC,CAAC;IACrD,KAAK,IAAIvF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC,KAAK,IAAIsF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzD,SAAS,CAAChD,MAAM,EAAEyG,CAAC,EAAE,EAAE;QACzCK,SAAS,CAAC3F,CAAC,CAAC,IAAI+B,gBAAgB,CAACuD,CAAC,CAAC,CAACtF,CAAC,CAAC,GAAG8B,MAAM,CAACwD,CAAC,CAAC;MACpD;IACF;IACAxD,MAAM,CAAC+D,MAAM,CAAC,CAAC,EAAE/D,MAAM,CAACjD,MAAM,EAAE,GAAG8G,SAAS,CAAC;EAC/C;;EAEA;EACA,MAAMG,eAAe,GAAGjE,SAAS,CAC9BpD,GAAG,CAAC,CAACmE,QAAQ,EAAET,KAAK,MAAM;IAAES,QAAQ;IAAEpB,KAAK,EAAEM,MAAM,CAACK,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CACrEC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAEqC,YAAY,CAAC,CACtBxC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACF,KAAK,GAAGG,CAAC,CAACH,KAAK,CAAC;EAEpC,MAAM6C,OAAO,GAAGc,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC,CAACqC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMxE,iBAAiB,GAAGqF,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC;;EAEpE;EACA,MAAMsC,cAAc,GAAG5E,uBAAuB,CAAC/B,IAAI,EAAEyG,OAAO,EAAEvE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAMsD,iBAAiB,GAAGvD,yBAAyB,CAACC,SAAS,EAAEC,MAAM,EAAEC,gBAAgB,CAAC;EAExF,OAAO;IACLqD,MAAM,EAAE,SAAS;IACjBJ,OAAO;IACPnD,SAAS,EAAEpB,iBAAiB;IAC5B4E,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH;;AAEA;AACA,OAAO,eAAegB,aAAaA,CAAC5H,IAAY,EAAEqG,YAAoB,GAAG,CAAC,EAA0B;EAClG,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAMlD,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAI;IAAA,IAAA6H,QAAA;IACF;IACA,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,qEAAqE,EAAE;MAClGlB,MAAM,EAAE,MAAM;MACdmB,OAAO,EAAE;QACP,cAAc,EAAE;MAClB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBC,MAAM,EAAEpI,IAAI,CAACgE,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC;QAAE;QAC7BqE,UAAU,EAAE;UACVC,UAAU,EAAE3G,IAAI,CAACsC,GAAG,CAAC,GAAG,EAAEoC,YAAY,GAAG,EAAE,CAAC;UAC5CkC,UAAU,EAAE5G,IAAI,CAACsC,GAAG,CAAC,EAAE,EAAEoC,YAAY,GAAG,EAAE,CAAC;UAC3CmC,SAAS,EAAE;QACb;MACF,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACV,QAAQ,CAACW,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,mBAAmBZ,QAAQ,CAACa,MAAM,EAAE,CAAC;IACvD;IAEA,MAAMC,MAAM,GAAG,MAAMd,QAAQ,CAACe,IAAI,CAAC,CAAC;IACpC,IAAIpC,OAAO,GAAG,EAAAoB,QAAA,GAAAe,MAAM,CAAC,CAAC,CAAC,cAAAf,QAAA,uBAATA,QAAA,CAAWiB,YAAY,KAAI9I,IAAI,CAACgE,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,KAAK;;IAEnE;IACA,MAAM+E,gBAAgB,GAAGhJ,iBAAiB,CAAC0G,OAAO,CAAC;;IAEnD;IACA,MAAME,cAAc,GAAG5E,uBAAuB,CAAC/B,IAAI,EAAEyG,OAAO,EAAEsC,gBAAgB,EAAEzF,SAAS,CAAC;;IAE1F;IACA,MAAM0F,cAAwB,GAAG1F,SAAS,CAACpD,GAAG,CAAEmE,QAAgB,IAAK;MACnE,OAAO9D,gBAAgB,CAAC8D,QAAQ,EAAEoC,OAAO,CAAC;IAC5C,CAAC,CAAC;;IAEF;IACA,MAAMjD,gBAA4B,GAAG,EAAE;IACvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;MACxB,KAAK,IAAIsF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzD,SAAS,CAAChD,MAAM,EAAEyG,CAAC,EAAE,EAAE;QACzCvD,gBAAgB,CAAC/B,CAAC,CAAC,CAACsF,CAAC,CAAC,GAAGtF,CAAC,KAAKsF,CAAC,GAAG,CAAC,GAAGxG,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACyD,CAAC,CAAC,CAAC;MACrF;IACF;;IAEA;IACA,MAAMH,iBAAiB,GAAGvD,yBAAyB,CAACC,SAAS,EAAE0F,cAAc,EAAExF,gBAAgB,CAAC;IAEhG,OAAO;MACLqD,MAAM,EAAE,MAAM;MACdJ,OAAO;MACPnD,SAAS,EAAEyF,gBAAgB;MAC3BjC,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EAEH,CAAC,CAAC,OAAOqC,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,4BAA4B,EAAEA,KAAK,CAAC;;IAElD;IACA,MAAMjE,KAAK,GAAGhF,IAAI,CAACW,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;IACxD,MAAM6C,QAAmC,GAAG,CAAC,CAAC;IAE9CF,KAAK,CAACG,OAAO,CAAEjE,IAAY,IAAK;MAC9B,IAAIA,IAAI,CAACZ,MAAM,GAAG,CAAC,EAAE;QACnB4E,QAAQ,CAAChE,IAAI,CAAC,GAAG,CAACgE,QAAQ,CAAChE,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;MAC5C;IACF,CAAC,CAAC;IAEF,MAAM8H,cAAwB,GAAG1F,SAAS,CAACpD,GAAG,CAAEmE,QAAgB,IAAK;MACnE,MAAM8E,aAAuB,GAAG9E,QAAQ,CAAC1D,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;MAC9E,MAAMY,KAAa,GAAGkG,aAAa,CAAC7H,MAAM,CAAC,CAACC,GAAW,EAAEL,IAAY,KAAKK,GAAG,IAAI2D,QAAQ,CAAChE,IAAI,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC;MACzG,OAAO+B,KAAK,GAAGkG,aAAa,CAAC7I,MAAM;IACrC,CAAC,CAAC;IAEF,MAAMiH,eAAe,GAAGjE,SAAS,CAC9BpD,GAAG,CAAC,CAACmE,QAAQ,EAAET,KAAK,MAAM;MAAES,QAAQ;MAAEpB,KAAK,EAAE+F,cAAc,CAACpF,KAAK,CAAC;MAAEA;IAAM,CAAC,CAAC,CAAC,CAC7EC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAEqC,YAAY,CAAC,CACtBxC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACF,KAAK,GAAGG,CAAC,CAACH,KAAK,CAAC;IAEpC,MAAM6C,OAAO,GAAGc,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC,CAACqC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC3E,MAAMxE,iBAAiB,GAAGqF,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC;IACpE,MAAMsC,cAAc,GAAG5E,uBAAuB,CAAC/B,IAAI,EAAEyG,OAAO,EAAEvE,iBAAiB,EAAEoB,SAAS,CAAC;IAE3F,MAAME,gBAA4B,GAAG,EAAE;IACvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;MACxB,KAAK,IAAIsF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzD,SAAS,CAAChD,MAAM,EAAEyG,CAAC,EAAE,EAAE;QACzCvD,gBAAgB,CAAC/B,CAAC,CAAC,CAACsF,CAAC,CAAC,GAAGtF,CAAC,KAAKsF,CAAC,GAAG,CAAC,GAAGxG,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACyD,CAAC,CAAC,CAAC;MACrF;IACF;IAEA,MAAMH,iBAAiB,GAAGvD,yBAAyB,CAACC,SAAS,EAAE0F,cAAc,EAAExF,gBAAgB,CAAC;IAEhG,OAAO;MACLqD,MAAM,EAAE,iBAAiB;MACzBJ,OAAO;MACPnD,SAAS,EAAEpB,iBAAiB;MAC5B4E,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;AACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}