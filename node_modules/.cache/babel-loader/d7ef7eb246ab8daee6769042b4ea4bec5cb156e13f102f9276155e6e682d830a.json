{"ast":null,"code":"import Sentiment from 'sentiment';\n// Simple sentence tokenizer\nfunction tokenizeSentences(text) {\n  return text.split(/[.!?]+/).map(s => s.trim()).filter(s => s.length > 10);\n}\n\n// Calculate cosine similarity between two sentences\nfunction cosineSimilarity(sent1, sent2) {\n  const words1 = sent1.toLowerCase().split(/\\s+/);\n  const words2 = sent2.toLowerCase().split(/\\s+/);\n  const allWords = Array.from(new Set([...words1, ...words2]));\n  const vector1 = allWords.map(word => words1.filter(w => w === word).length);\n  const vector2 = allWords.map(word => words2.filter(w => w === word).length);\n  const dotProduct = vector1.reduce((sum, val, i) => sum + val * vector2[i], 0);\n  const magnitude1 = Math.sqrt(vector1.reduce((sum, val) => sum + val * val, 0));\n  const magnitude2 = Math.sqrt(vector2.reduce((sum, val) => sum + val * val, 0));\n  return magnitude1 && magnitude2 ? dotProduct / (magnitude1 * magnitude2) : 0;\n}\n\n// Initialize sentiment analyzer\nconst sentiment = new Sentiment();\n\n// Calculate quality metrics for a summary\nfunction calculateQualityMetrics(originalText, summaryText, selectedSentences, allSentences) {\n  // Coverage: ratio of unique words in summary vs original\n  const originalWords = new Set(originalText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const summaryWords = new Set(summaryText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const coverage = summaryWords.size / originalWords.size;\n\n  // Coherence: average similarity between consecutive sentences in summary\n  let coherenceSum = 0;\n  for (let i = 0; i < selectedSentences.length - 1; i++) {\n    coherenceSum += cosineSimilarity(selectedSentences[i], selectedSentences[i + 1]);\n  }\n  const coherence = selectedSentences.length > 1 ? coherenceSum / (selectedSentences.length - 1) : 1;\n\n  // Diversity: ratio of unique words to total words in summary\n  const totalSummaryWords = summaryText.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const diversity = summaryWords.size / totalSummaryWords.length;\n\n  // Confidence: weighted combination of metrics\n  const confidence = coverage * 0.4 + coherence * 0.3 + diversity * 0.3;\n\n  // Sentiment analysis\n  const sentimentResult = sentiment.analyze(summaryText);\n  return {\n    coverage: Math.round(coverage * 100) / 100,\n    coherence: Math.round(coherence * 100) / 100,\n    diversity: Math.round(diversity * 100) / 100,\n    confidence: Math.round(confidence * 100) / 100,\n    sentiment: {\n      score: sentimentResult.score,\n      comparative: Math.round(sentimentResult.comparative * 100) / 100,\n      positive: sentimentResult.positive,\n      negative: sentimentResult.negative\n    }\n  };\n}\n\n// Generate visualization data\nfunction generateVisualizationData(sentences, scores, similarityMatrix) {\n  // Limit visualization to top 25 sentences to improve performance\n  const MAX_NODES = 25;\n\n  // Get indices of top scoring sentences\n  const rankedIndices = sentences.map((_, index) => ({\n    index,\n    score: scores[index] || 0\n  })).sort((a, b) => b.score - a.score).slice(0, Math.min(MAX_NODES, sentences.length)).map(item => item.index);\n\n  // Create sentence nodes for graph visualization (only for top sentences)\n  const sentenceGraph = rankedIndices.map(originalIndex => {\n    const sentence = sentences[originalIndex];\n    const sentimentScore = sentiment.analyze(sentence).comparative;\n\n    // Only create connections to other top sentences\n    const connections = rankedIndices.map((targetIndex, j) => {\n      var _similarityMatrix$ori;\n      return {\n        target: `sentence-${targetIndex}`,\n        weight: ((_similarityMatrix$ori = similarityMatrix[originalIndex]) === null || _similarityMatrix$ori === void 0 ? void 0 : _similarityMatrix$ori[targetIndex]) || 0\n      };\n    }).filter(conn => conn.weight > 0.1 && conn.target !== `sentence-${originalIndex}`);\n    return {\n      id: `sentence-${originalIndex}`,\n      text: sentence.slice(0, 100) + (sentence.length > 100 ? '...' : ''),\n      score: scores[originalIndex] || 0,\n      sentiment: sentimentScore,\n      connections\n    };\n  });\n\n  // Simple topic clustering based on word overlap\n  const topicClusters = generateTopicClusters(sentences);\n  return {\n    sentenceGraph,\n    topicClusters\n  };\n}\n\n// Generate topic clusters using simple k-means-like approach\nfunction generateTopicClusters(sentences) {\n  const words = sentences.flatMap(s => s.toLowerCase().match(/\\b\\w{4,}\\b/g) || []);\n  const wordFreq = {};\n  words.forEach(word => {\n    wordFreq[word] = (wordFreq[word] || 0) + 1;\n  });\n\n  // Get top keywords\n  const topWords = Object.entries(wordFreq).sort(([, a], [, b]) => b - a).slice(0, 12).map(([word]) => word);\n\n  // Create clusters based on keyword presence\n  const clusters = [];\n  const colors = ['#3B82F6', '#EF4444', '#10B981', '#F59E0B'];\n  for (let i = 0; i < Math.min(3, Math.ceil(topWords.length / 4)); i++) {\n    const clusterKeywords = topWords.slice(i * 4, (i + 1) * 4);\n    const clusterSentences = sentences.filter(sentence => clusterKeywords.some(keyword => sentence.toLowerCase().includes(keyword)));\n    if (clusterSentences.length > 0) {\n      clusters.push({\n        id: `cluster-${i}`,\n        keywords: clusterKeywords,\n        sentences: clusterSentences.map(s => s.slice(0, 80) + '...'),\n        centroid: [Math.random() * 100, Math.random() * 100],\n        // Simplified\n        color: colors[i % colors.length]\n      });\n    }\n  }\n  return clusters;\n}\n\n// TextRank implementation\nexport function textRankSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'TextRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Build similarity matrix\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      if (i === j) {\n        similarityMatrix[i][j] = 0;\n      } else {\n        similarityMatrix[i][j] = cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n  }\n\n  // PageRank algorithm\n  const scores = new Array(sentences.length).fill(1);\n  const damping = 0.85;\n  const iterations = 50;\n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = [...scores];\n    for (let i = 0; i < sentences.length; i++) {\n      let sum = 0;\n      for (let j = 0; j < sentences.length; j++) {\n        if (i !== j) {\n          const totalSim = similarityMatrix[j].reduce((a, b) => a + b, 0);\n          if (totalSim > 0) {\n            sum += similarityMatrix[j][i] / totalSim * scores[j];\n          }\n        }\n      }\n      newScores[i] = 1 - damping + damping * sum;\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: scores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  return {\n    method: 'TextRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// LexRank implementation\nexport function lexRankSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'LexRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Build similarity matrix\n  const threshold = 0.1;\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      const similarity = cosineSimilarity(sentences[i], sentences[j]);\n      similarityMatrix[i][j] = similarity > threshold ? similarity : 0;\n    }\n  }\n\n  // Normalize rows\n  for (let i = 0; i < sentences.length; i++) {\n    const rowSum = similarityMatrix[i].reduce((a, b) => a + b, 0);\n    if (rowSum > 0) {\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] /= rowSum;\n      }\n    }\n  }\n\n  // Power iteration\n  const scores = new Array(sentences.length).fill(1 / sentences.length);\n  const iterations = 50;\n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = new Array(sentences.length).fill(0);\n    for (let i = 0; i < sentences.length; i++) {\n      for (let j = 0; j < sentences.length; j++) {\n        newScores[i] += similarityMatrix[j][i] * scores[j];\n      }\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: scores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  return {\n    method: 'LexRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// Simple extractive summarization (frequency-based)\nexport function frequencyBasedSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'Frequency-Based',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Calculate word frequencies\n  const words = text.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const wordFreq = {};\n  words.forEach(word => {\n    if (word.length > 3) {\n      // Ignore short words\n      wordFreq[word] = (wordFreq[word] || 0) + 1;\n    }\n  });\n\n  // Score sentences based on word frequencies\n  const sentenceScores = sentences.map(sentence => {\n    const sentenceWords = sentence.toLowerCase().match(/\\b\\w+\\b/g) || [];\n    const score = sentenceWords.reduce((sum, word) => sum + (wordFreq[word] || 0), 0);\n    return score / sentenceWords.length; // Normalize by sentence length\n  });\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: sentenceScores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Create a simple similarity matrix for visualization (based on word overlap)\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n    }\n  }\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n  return {\n    method: 'Frequency-Based',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}","map":{"version":3,"names":["Sentiment","tokenizeSentences","text","split","map","s","trim","filter","length","cosineSimilarity","sent1","sent2","words1","toLowerCase","words2","allWords","Array","from","Set","vector1","word","w","vector2","dotProduct","reduce","sum","val","i","magnitude1","Math","sqrt","magnitude2","sentiment","calculateQualityMetrics","originalText","summaryText","selectedSentences","allSentences","originalWords","match","summaryWords","coverage","size","coherenceSum","coherence","totalSummaryWords","diversity","confidence","sentimentResult","analyze","round","score","comparative","positive","negative","generateVisualizationData","sentences","scores","similarityMatrix","MAX_NODES","rankedIndices","_","index","sort","a","b","slice","min","item","sentenceGraph","originalIndex","sentence","sentimentScore","connections","targetIndex","j","_similarityMatrix$ori","target","weight","conn","id","topicClusters","generateTopicClusters","words","flatMap","wordFreq","forEach","topWords","Object","entries","clusters","colors","ceil","clusterKeywords","clusterSentences","some","keyword","includes","push","keywords","centroid","random","color","textRankSummarize","numSentences","startTime","Date","now","summary","join","qualityMetrics","visualizationData","method","processingTime","fill","damping","iterations","iter","newScores","totalSim","splice","rankedSentences","lexRankSummarize","threshold","similarity","rowSum","frequencyBasedSummarize","sentenceScores","sentenceWords"],"sources":["/Users/averyreyna/Codebases/rerank/src/utils/textSummarization.ts"],"sourcesContent":["import Sentiment from 'sentiment';\n\nexport interface QualityMetrics {\n  coverage: number;\n  coherence: number;\n  diversity: number;\n  confidence: number;\n  sentiment: {\n    score: number;\n    comparative: number;\n    positive: string[];\n    negative: string[];\n  };\n}\n\nexport interface SentenceNode {\n  id: string;\n  text: string;\n  score: number;\n  sentiment: number;\n  connections: { target: string; weight: number }[];\n  position?: { x: number; y: number };\n}\n\nexport interface TopicCluster {\n  id: string;\n  keywords: string[];\n  sentences: string[];\n  centroid: number[];\n  color: string;\n}\n\nexport interface SummaryResult {\n  method: string;\n  summary: string;\n  sentences: string[];\n  processingTime: number;\n  qualityMetrics: QualityMetrics;\n  visualizationData: {\n    sentenceGraph: SentenceNode[];\n    topicClusters: TopicCluster[];\n  };\n}\n\n// Simple sentence tokenizer\nfunction tokenizeSentences(text: string): string[] {\n  return text\n    .split(/[.!?]+/)\n    .map(s => s.trim())\n    .filter(s => s.length > 10);\n}\n\n// Calculate cosine similarity between two sentences\nfunction cosineSimilarity(sent1: string, sent2: string): number {\n  const words1 = sent1.toLowerCase().split(/\\s+/);\n  const words2 = sent2.toLowerCase().split(/\\s+/);\n  \n  const allWords = Array.from(new Set([...words1, ...words2]));\n  \n  const vector1 = allWords.map(word => words1.filter(w => w === word).length);\n  const vector2 = allWords.map(word => words2.filter(w => w === word).length);\n  \n  const dotProduct = vector1.reduce((sum, val, i) => sum + val * vector2[i], 0);\n  const magnitude1 = Math.sqrt(vector1.reduce((sum, val) => sum + val * val, 0));\n  const magnitude2 = Math.sqrt(vector2.reduce((sum, val) => sum + val * val, 0));\n  \n  return magnitude1 && magnitude2 ? dotProduct / (magnitude1 * magnitude2) : 0;\n}\n\n// Initialize sentiment analyzer\nconst sentiment = new Sentiment();\n\n// Calculate quality metrics for a summary\nfunction calculateQualityMetrics(\n  originalText: string, \n  summaryText: string, \n  selectedSentences: string[],\n  allSentences: string[]\n): QualityMetrics {\n  // Coverage: ratio of unique words in summary vs original\n  const originalWords = new Set(originalText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const summaryWords = new Set(summaryText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const coverage = summaryWords.size / originalWords.size;\n\n  // Coherence: average similarity between consecutive sentences in summary\n  let coherenceSum = 0;\n  for (let i = 0; i < selectedSentences.length - 1; i++) {\n    coherenceSum += cosineSimilarity(selectedSentences[i], selectedSentences[i + 1]);\n  }\n  const coherence = selectedSentences.length > 1 ? coherenceSum / (selectedSentences.length - 1) : 1;\n\n  // Diversity: ratio of unique words to total words in summary\n  const totalSummaryWords = summaryText.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const diversity = summaryWords.size / totalSummaryWords.length;\n\n  // Confidence: weighted combination of metrics\n  const confidence = (coverage * 0.4 + coherence * 0.3 + diversity * 0.3);\n\n  // Sentiment analysis\n  const sentimentResult = sentiment.analyze(summaryText);\n\n  return {\n    coverage: Math.round(coverage * 100) / 100,\n    coherence: Math.round(coherence * 100) / 100,\n    diversity: Math.round(diversity * 100) / 100,\n    confidence: Math.round(confidence * 100) / 100,\n    sentiment: {\n      score: sentimentResult.score,\n      comparative: Math.round(sentimentResult.comparative * 100) / 100,\n      positive: sentimentResult.positive,\n      negative: sentimentResult.negative\n    }\n  };\n}\n\n// Generate visualization data\nfunction generateVisualizationData(\n  sentences: string[], \n  scores: number[], \n  similarityMatrix: number[][]\n): { sentenceGraph: SentenceNode[]; topicClusters: TopicCluster[] } {\n  // Limit visualization to top 25 sentences to improve performance\n  const MAX_NODES = 25;\n  \n  // Get indices of top scoring sentences\n  const rankedIndices = sentences\n    .map((_, index) => ({ index, score: scores[index] || 0 }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, Math.min(MAX_NODES, sentences.length))\n    .map(item => item.index);\n\n  // Create sentence nodes for graph visualization (only for top sentences)\n  const sentenceGraph: SentenceNode[] = rankedIndices.map((originalIndex) => {\n    const sentence = sentences[originalIndex];\n    const sentimentScore = sentiment.analyze(sentence).comparative;\n    \n    // Only create connections to other top sentences\n    const connections = rankedIndices.map((targetIndex, j) => ({\n      target: `sentence-${targetIndex}`,\n      weight: similarityMatrix[originalIndex]?.[targetIndex] || 0\n    })).filter(conn => conn.weight > 0.1 && conn.target !== `sentence-${originalIndex}`);\n\n    return {\n      id: `sentence-${originalIndex}`,\n      text: sentence.slice(0, 100) + (sentence.length > 100 ? '...' : ''),\n      score: scores[originalIndex] || 0,\n      sentiment: sentimentScore,\n      connections\n    };\n  });\n\n  // Simple topic clustering based on word overlap\n  const topicClusters = generateTopicClusters(sentences);\n\n  return { sentenceGraph, topicClusters };\n}\n\n// Generate topic clusters using simple k-means-like approach\nfunction generateTopicClusters(sentences: string[]): TopicCluster[] {\n  const words = sentences.flatMap(s => \n    s.toLowerCase().match(/\\b\\w{4,}\\b/g) || []\n  );\n  \n  const wordFreq: { [key: string]: number } = {};\n  words.forEach(word => {\n    wordFreq[word] = (wordFreq[word] || 0) + 1;\n  });\n\n  // Get top keywords\n  const topWords = Object.entries(wordFreq)\n    .sort(([,a], [,b]) => b - a)\n    .slice(0, 12)\n    .map(([word]) => word);\n\n  // Create clusters based on keyword presence\n  const clusters: TopicCluster[] = [];\n  const colors = ['#3B82F6', '#EF4444', '#10B981', '#F59E0B'];\n  \n  for (let i = 0; i < Math.min(3, Math.ceil(topWords.length / 4)); i++) {\n    const clusterKeywords = topWords.slice(i * 4, (i + 1) * 4);\n    const clusterSentences = sentences.filter(sentence => \n      clusterKeywords.some(keyword => \n        sentence.toLowerCase().includes(keyword)\n      )\n    );\n\n    if (clusterSentences.length > 0) {\n      clusters.push({\n        id: `cluster-${i}`,\n        keywords: clusterKeywords,\n        sentences: clusterSentences.map(s => s.slice(0, 80) + '...'),\n        centroid: [Math.random() * 100, Math.random() * 100], // Simplified\n        color: colors[i % colors.length]\n      });\n    }\n  }\n\n  return clusters;\n}\n\n// TextRank implementation\nexport function textRankSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'TextRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Build similarity matrix\n  const similarityMatrix: number[][] = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      if (i === j) {\n        similarityMatrix[i][j] = 0;\n      } else {\n        similarityMatrix[i][j] = cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n  }\n  \n  // PageRank algorithm\n  const scores = new Array(sentences.length).fill(1);\n  const damping = 0.85;\n  const iterations = 50;\n  \n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = [...scores];\n    for (let i = 0; i < sentences.length; i++) {\n      let sum = 0;\n      for (let j = 0; j < sentences.length; j++) {\n        if (i !== j) {\n          const totalSim = similarityMatrix[j].reduce((a, b) => a + b, 0);\n          if (totalSim > 0) {\n            sum += (similarityMatrix[j][i] / totalSim) * scores[j];\n          }\n        }\n      }\n      newScores[i] = (1 - damping) + damping * sum;\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: scores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  \n  return {\n    method: 'TextRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// LexRank implementation\nexport function lexRankSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'LexRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Build similarity matrix\n  const threshold = 0.1;\n  const similarityMatrix: number[][] = [];\n  \n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      const similarity = cosineSimilarity(sentences[i], sentences[j]);\n      similarityMatrix[i][j] = similarity > threshold ? similarity : 0;\n    }\n  }\n  \n  // Normalize rows\n  for (let i = 0; i < sentences.length; i++) {\n    const rowSum = similarityMatrix[i].reduce((a, b) => a + b, 0);\n    if (rowSum > 0) {\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] /= rowSum;\n      }\n    }\n  }\n  \n  // Power iteration\n  const scores = new Array(sentences.length).fill(1 / sentences.length);\n  const iterations = 50;\n  \n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = new Array(sentences.length).fill(0);\n    for (let i = 0; i < sentences.length; i++) {\n      for (let j = 0; j < sentences.length; j++) {\n        newScores[i] += similarityMatrix[j][i] * scores[j];\n      }\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: scores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  \n  return {\n    method: 'LexRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// Simple extractive summarization (frequency-based)\nexport function frequencyBasedSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'Frequency-Based',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Calculate word frequencies\n  const words = text.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const wordFreq: { [key: string]: number } = {};\n  \n  words.forEach((word: string) => {\n    if (word.length > 3) { // Ignore short words\n      wordFreq[word] = (wordFreq[word] || 0) + 1;\n    }\n  });\n  \n  // Score sentences based on word frequencies\n  const sentenceScores: number[] = sentences.map((sentence: string) => {\n    const sentenceWords: string[] = sentence.toLowerCase().match(/\\b\\w+\\b/g) || [];\n    const score: number = sentenceWords.reduce((sum: number, word: string) => sum + (wordFreq[word] || 0), 0);\n    return score / sentenceWords.length; // Normalize by sentence length\n  });\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: sentenceScores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Create a simple similarity matrix for visualization (based on word overlap)\n  const similarityMatrix: number[][] = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n    }\n  }\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n  \n  return {\n    method: 'Frequency-Based',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n"],"mappings":"AAAA,OAAOA,SAAS,MAAM,WAAW;AA4CjC;AACA,SAASC,iBAAiBA,CAACC,IAAY,EAAY;EACjD,OAAOA,IAAI,CACRC,KAAK,CAAC,QAAQ,CAAC,CACfC,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACC,IAAI,CAAC,CAAC,CAAC,CAClBC,MAAM,CAACF,CAAC,IAAIA,CAAC,CAACG,MAAM,GAAG,EAAE,CAAC;AAC/B;;AAEA;AACA,SAASC,gBAAgBA,CAACC,KAAa,EAAEC,KAAa,EAAU;EAC9D,MAAMC,MAAM,GAAGF,KAAK,CAACG,WAAW,CAAC,CAAC,CAACV,KAAK,CAAC,KAAK,CAAC;EAC/C,MAAMW,MAAM,GAAGH,KAAK,CAACE,WAAW,CAAC,CAAC,CAACV,KAAK,CAAC,KAAK,CAAC;EAE/C,MAAMY,QAAQ,GAAGC,KAAK,CAACC,IAAI,CAAC,IAAIC,GAAG,CAAC,CAAC,GAAGN,MAAM,EAAE,GAAGE,MAAM,CAAC,CAAC,CAAC;EAE5D,MAAMK,OAAO,GAAGJ,QAAQ,CAACX,GAAG,CAACgB,IAAI,IAAIR,MAAM,CAACL,MAAM,CAACc,CAAC,IAAIA,CAAC,KAAKD,IAAI,CAAC,CAACZ,MAAM,CAAC;EAC3E,MAAMc,OAAO,GAAGP,QAAQ,CAACX,GAAG,CAACgB,IAAI,IAAIN,MAAM,CAACP,MAAM,CAACc,CAAC,IAAIA,CAAC,KAAKD,IAAI,CAAC,CAACZ,MAAM,CAAC;EAE3E,MAAMe,UAAU,GAAGJ,OAAO,CAACK,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,EAAEC,CAAC,KAAKF,GAAG,GAAGC,GAAG,GAAGJ,OAAO,CAACK,CAAC,CAAC,EAAE,CAAC,CAAC;EAC7E,MAAMC,UAAU,GAAGC,IAAI,CAACC,IAAI,CAACX,OAAO,CAACK,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAGC,GAAG,GAAGA,GAAG,EAAE,CAAC,CAAC,CAAC;EAC9E,MAAMK,UAAU,GAAGF,IAAI,CAACC,IAAI,CAACR,OAAO,CAACE,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAGC,GAAG,GAAGA,GAAG,EAAE,CAAC,CAAC,CAAC;EAE9E,OAAOE,UAAU,IAAIG,UAAU,GAAGR,UAAU,IAAIK,UAAU,GAAGG,UAAU,CAAC,GAAG,CAAC;AAC9E;;AAEA;AACA,MAAMC,SAAS,GAAG,IAAIhC,SAAS,CAAC,CAAC;;AAEjC;AACA,SAASiC,uBAAuBA,CAC9BC,YAAoB,EACpBC,WAAmB,EACnBC,iBAA2B,EAC3BC,YAAsB,EACN;EAChB;EACA,MAAMC,aAAa,GAAG,IAAIpB,GAAG,CAACgB,YAAY,CAACrB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC;EACjF,MAAMC,YAAY,GAAG,IAAItB,GAAG,CAACiB,WAAW,CAACtB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC;EAC/E,MAAME,QAAQ,GAAGD,YAAY,CAACE,IAAI,GAAGJ,aAAa,CAACI,IAAI;;EAEvD;EACA,IAAIC,YAAY,GAAG,CAAC;EACpB,KAAK,IAAIhB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGS,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,EAAEmB,CAAC,EAAE,EAAE;IACrDgB,YAAY,IAAIlC,gBAAgB,CAAC2B,iBAAiB,CAACT,CAAC,CAAC,EAAES,iBAAiB,CAACT,CAAC,GAAG,CAAC,CAAC,CAAC;EAClF;EACA,MAAMiB,SAAS,GAAGR,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,GAAGmC,YAAY,IAAIP,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC;;EAElG;EACA,MAAMqC,iBAAiB,GAAGV,WAAW,CAACtB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;EAC3E,MAAMO,SAAS,GAAGN,YAAY,CAACE,IAAI,GAAGG,iBAAiB,CAACrC,MAAM;;EAE9D;EACA,MAAMuC,UAAU,GAAIN,QAAQ,GAAG,GAAG,GAAGG,SAAS,GAAG,GAAG,GAAGE,SAAS,GAAG,GAAI;;EAEvE;EACA,MAAME,eAAe,GAAGhB,SAAS,CAACiB,OAAO,CAACd,WAAW,CAAC;EAEtD,OAAO;IACLM,QAAQ,EAAEZ,IAAI,CAACqB,KAAK,CAACT,QAAQ,GAAG,GAAG,CAAC,GAAG,GAAG;IAC1CG,SAAS,EAAEf,IAAI,CAACqB,KAAK,CAACN,SAAS,GAAG,GAAG,CAAC,GAAG,GAAG;IAC5CE,SAAS,EAAEjB,IAAI,CAACqB,KAAK,CAACJ,SAAS,GAAG,GAAG,CAAC,GAAG,GAAG;IAC5CC,UAAU,EAAElB,IAAI,CAACqB,KAAK,CAACH,UAAU,GAAG,GAAG,CAAC,GAAG,GAAG;IAC9Cf,SAAS,EAAE;MACTmB,KAAK,EAAEH,eAAe,CAACG,KAAK;MAC5BC,WAAW,EAAEvB,IAAI,CAACqB,KAAK,CAACF,eAAe,CAACI,WAAW,GAAG,GAAG,CAAC,GAAG,GAAG;MAChEC,QAAQ,EAAEL,eAAe,CAACK,QAAQ;MAClCC,QAAQ,EAAEN,eAAe,CAACM;IAC5B;EACF,CAAC;AACH;;AAEA;AACA,SAASC,yBAAyBA,CAChCC,SAAmB,EACnBC,MAAgB,EAChBC,gBAA4B,EACsC;EAClE;EACA,MAAMC,SAAS,GAAG,EAAE;;EAEpB;EACA,MAAMC,aAAa,GAAGJ,SAAS,CAC5BpD,GAAG,CAAC,CAACyD,CAAC,EAAEC,KAAK,MAAM;IAAEA,KAAK;IAAEX,KAAK,EAAEM,MAAM,CAACK,KAAK,CAAC,IAAI;EAAE,CAAC,CAAC,CAAC,CACzDC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAErC,IAAI,CAACsC,GAAG,CAACR,SAAS,EAAEH,SAAS,CAAChD,MAAM,CAAC,CAAC,CAC/CJ,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACN,KAAK,CAAC;;EAE1B;EACA,MAAMO,aAA6B,GAAGT,aAAa,CAACxD,GAAG,CAAEkE,aAAa,IAAK;IACzE,MAAMC,QAAQ,GAAGf,SAAS,CAACc,aAAa,CAAC;IACzC,MAAME,cAAc,GAAGxC,SAAS,CAACiB,OAAO,CAACsB,QAAQ,CAAC,CAACnB,WAAW;;IAE9D;IACA,MAAMqB,WAAW,GAAGb,aAAa,CAACxD,GAAG,CAAC,CAACsE,WAAW,EAAEC,CAAC;MAAA,IAAAC,qBAAA;MAAA,OAAM;QACzDC,MAAM,EAAE,YAAYH,WAAW,EAAE;QACjCI,MAAM,EAAE,EAAAF,qBAAA,GAAAlB,gBAAgB,CAACY,aAAa,CAAC,cAAAM,qBAAA,uBAA/BA,qBAAA,CAAkCF,WAAW,CAAC,KAAI;MAC5D,CAAC;IAAA,CAAC,CAAC,CAACnE,MAAM,CAACwE,IAAI,IAAIA,IAAI,CAACD,MAAM,GAAG,GAAG,IAAIC,IAAI,CAACF,MAAM,KAAK,YAAYP,aAAa,EAAE,CAAC;IAEpF,OAAO;MACLU,EAAE,EAAE,YAAYV,aAAa,EAAE;MAC/BpE,IAAI,EAAEqE,QAAQ,CAACL,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,IAAIK,QAAQ,CAAC/D,MAAM,GAAG,GAAG,GAAG,KAAK,GAAG,EAAE,CAAC;MACnE2C,KAAK,EAAEM,MAAM,CAACa,aAAa,CAAC,IAAI,CAAC;MACjCtC,SAAS,EAAEwC,cAAc;MACzBC;IACF,CAAC;EACH,CAAC,CAAC;;EAEF;EACA,MAAMQ,aAAa,GAAGC,qBAAqB,CAAC1B,SAAS,CAAC;EAEtD,OAAO;IAAEa,aAAa;IAAEY;EAAc,CAAC;AACzC;;AAEA;AACA,SAASC,qBAAqBA,CAAC1B,SAAmB,EAAkB;EAClE,MAAM2B,KAAK,GAAG3B,SAAS,CAAC4B,OAAO,CAAC/E,CAAC,IAC/BA,CAAC,CAACQ,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,aAAa,CAAC,IAAI,EAC1C,CAAC;EAED,MAAM8C,QAAmC,GAAG,CAAC,CAAC;EAC9CF,KAAK,CAACG,OAAO,CAAClE,IAAI,IAAI;IACpBiE,QAAQ,CAACjE,IAAI,CAAC,GAAG,CAACiE,QAAQ,CAACjE,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;EAC5C,CAAC,CAAC;;EAEF;EACA,MAAMmE,QAAQ,GAAGC,MAAM,CAACC,OAAO,CAACJ,QAAQ,CAAC,CACtCtB,IAAI,CAAC,CAAC,GAAEC,CAAC,CAAC,EAAE,GAAEC,CAAC,CAAC,KAAKA,CAAC,GAAGD,CAAC,CAAC,CAC3BE,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,CACZ9D,GAAG,CAAC,CAAC,CAACgB,IAAI,CAAC,KAAKA,IAAI,CAAC;;EAExB;EACA,MAAMsE,QAAwB,GAAG,EAAE;EACnC,MAAMC,MAAM,GAAG,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;EAE3D,KAAK,IAAIhE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGE,IAAI,CAACsC,GAAG,CAAC,CAAC,EAAEtC,IAAI,CAAC+D,IAAI,CAACL,QAAQ,CAAC/E,MAAM,GAAG,CAAC,CAAC,CAAC,EAAEmB,CAAC,EAAE,EAAE;IACpE,MAAMkE,eAAe,GAAGN,QAAQ,CAACrB,KAAK,CAACvC,CAAC,GAAG,CAAC,EAAE,CAACA,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IAC1D,MAAMmE,gBAAgB,GAAGtC,SAAS,CAACjD,MAAM,CAACgE,QAAQ,IAChDsB,eAAe,CAACE,IAAI,CAACC,OAAO,IAC1BzB,QAAQ,CAAC1D,WAAW,CAAC,CAAC,CAACoF,QAAQ,CAACD,OAAO,CACzC,CACF,CAAC;IAED,IAAIF,gBAAgB,CAACtF,MAAM,GAAG,CAAC,EAAE;MAC/BkF,QAAQ,CAACQ,IAAI,CAAC;QACZlB,EAAE,EAAE,WAAWrD,CAAC,EAAE;QAClBwE,QAAQ,EAAEN,eAAe;QACzBrC,SAAS,EAAEsC,gBAAgB,CAAC1F,GAAG,CAACC,CAAC,IAAIA,CAAC,CAAC6D,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,GAAG,KAAK,CAAC;QAC5DkC,QAAQ,EAAE,CAACvE,IAAI,CAACwE,MAAM,CAAC,CAAC,GAAG,GAAG,EAAExE,IAAI,CAACwE,MAAM,CAAC,CAAC,GAAG,GAAG,CAAC;QAAE;QACtDC,KAAK,EAAEX,MAAM,CAAChE,CAAC,GAAGgE,MAAM,CAACnF,MAAM;MACjC,CAAC,CAAC;IACJ;EACF;EAEA,OAAOkF,QAAQ;AACjB;;AAEA;AACA,OAAO,SAASa,iBAAiBA,CAACrG,IAAY,EAAEsG,YAAoB,GAAG,CAAC,EAAiB;EACvF,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAMnD,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAIgG,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAGpD,SAAS,CAACqD,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAG7E,uBAAuB,CAAC/B,IAAI,EAAE0G,OAAO,EAAEpD,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMuD,iBAAiB,GAAGxD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACL4G,MAAM,EAAE,UAAU;MAClBJ,OAAO;MACPpD,SAAS;MACTyD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAMrD,gBAA4B,GAAG,EAAE;EACvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIgD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,SAAS,CAAChD,MAAM,EAAEmE,CAAC,EAAE,EAAE;MACzC,IAAIhD,CAAC,KAAKgD,CAAC,EAAE;QACXjB,gBAAgB,CAAC/B,CAAC,CAAC,CAACgD,CAAC,CAAC,GAAG,CAAC;MAC5B,CAAC,MAAM;QACLjB,gBAAgB,CAAC/B,CAAC,CAAC,CAACgD,CAAC,CAAC,GAAGlE,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACmB,CAAC,CAAC,CAAC;MACvE;IACF;EACF;;EAEA;EACA,MAAMlB,MAAM,GAAG,IAAIzC,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAAC0G,IAAI,CAAC,CAAC,CAAC;EAClD,MAAMC,OAAO,GAAG,IAAI;EACpB,MAAMC,UAAU,GAAG,EAAE;EAErB,KAAK,IAAIC,IAAI,GAAG,CAAC,EAAEA,IAAI,GAAGD,UAAU,EAAEC,IAAI,EAAE,EAAE;IAC5C,MAAMC,SAAS,GAAG,CAAC,GAAG7D,MAAM,CAAC;IAC7B,KAAK,IAAI9B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC,IAAIF,GAAG,GAAG,CAAC;MACX,KAAK,IAAIkD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,SAAS,CAAChD,MAAM,EAAEmE,CAAC,EAAE,EAAE;QACzC,IAAIhD,CAAC,KAAKgD,CAAC,EAAE;UACX,MAAM4C,QAAQ,GAAG7D,gBAAgB,CAACiB,CAAC,CAAC,CAACnD,MAAM,CAAC,CAACwC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC;UAC/D,IAAIsD,QAAQ,GAAG,CAAC,EAAE;YAChB9F,GAAG,IAAKiC,gBAAgB,CAACiB,CAAC,CAAC,CAAChD,CAAC,CAAC,GAAG4F,QAAQ,GAAI9D,MAAM,CAACkB,CAAC,CAAC;UACxD;QACF;MACF;MACA2C,SAAS,CAAC3F,CAAC,CAAC,GAAI,CAAC,GAAGwF,OAAO,GAAIA,OAAO,GAAG1F,GAAG;IAC9C;IACAgC,MAAM,CAAC+D,MAAM,CAAC,CAAC,EAAE/D,MAAM,CAACjD,MAAM,EAAE,GAAG8G,SAAS,CAAC;EAC/C;;EAEA;EACA,MAAMG,eAAe,GAAGjE,SAAS,CAC9BpD,GAAG,CAAC,CAACmE,QAAQ,EAAET,KAAK,MAAM;IAAES,QAAQ;IAAEpB,KAAK,EAAEM,MAAM,CAACK,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CACrEC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAEsC,YAAY,CAAC,CACtBzC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACF,KAAK,GAAGG,CAAC,CAACH,KAAK,CAAC;EAEpC,MAAM8C,OAAO,GAAGa,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC,CAACsC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMzE,iBAAiB,GAAGqF,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC;;EAEpE;EACA,MAAMuC,cAAc,GAAG7E,uBAAuB,CAAC/B,IAAI,EAAE0G,OAAO,EAAExE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAMuD,iBAAiB,GAAGxD,yBAAyB,CAACC,SAAS,EAAEC,MAAM,EAAEC,gBAAgB,CAAC;EAExF,OAAO;IACLsD,MAAM,EAAE,UAAU;IAClBJ,OAAO;IACPpD,SAAS,EAAEpB,iBAAiB;IAC5B6E,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH;;AAEA;AACA,OAAO,SAASW,gBAAgBA,CAACxH,IAAY,EAAEsG,YAAoB,GAAG,CAAC,EAAiB;EACtF,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAMnD,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAIgG,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAGpD,SAAS,CAACqD,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAG7E,uBAAuB,CAAC/B,IAAI,EAAE0G,OAAO,EAAEpD,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMuD,iBAAiB,GAAGxD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACL4G,MAAM,EAAE,SAAS;MACjBJ,OAAO;MACPpD,SAAS;MACTyD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAMY,SAAS,GAAG,GAAG;EACrB,MAAMjE,gBAA4B,GAAG,EAAE;EAEvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIgD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,SAAS,CAAChD,MAAM,EAAEmE,CAAC,EAAE,EAAE;MACzC,MAAMiD,UAAU,GAAGnH,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACmB,CAAC,CAAC,CAAC;MAC/DjB,gBAAgB,CAAC/B,CAAC,CAAC,CAACgD,CAAC,CAAC,GAAGiD,UAAU,GAAGD,SAAS,GAAGC,UAAU,GAAG,CAAC;IAClE;EACF;;EAEA;EACA,KAAK,IAAIjG,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC,MAAMkG,MAAM,GAAGnE,gBAAgB,CAAC/B,CAAC,CAAC,CAACH,MAAM,CAAC,CAACwC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC;IAC7D,IAAI4D,MAAM,GAAG,CAAC,EAAE;MACd,KAAK,IAAIlD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,SAAS,CAAChD,MAAM,EAAEmE,CAAC,EAAE,EAAE;QACzCjB,gBAAgB,CAAC/B,CAAC,CAAC,CAACgD,CAAC,CAAC,IAAIkD,MAAM;MAClC;IACF;EACF;;EAEA;EACA,MAAMpE,MAAM,GAAG,IAAIzC,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAAC0G,IAAI,CAAC,CAAC,GAAG1D,SAAS,CAAChD,MAAM,CAAC;EACrE,MAAM4G,UAAU,GAAG,EAAE;EAErB,KAAK,IAAIC,IAAI,GAAG,CAAC,EAAEA,IAAI,GAAGD,UAAU,EAAEC,IAAI,EAAE,EAAE;IAC5C,MAAMC,SAAS,GAAG,IAAItG,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAAC0G,IAAI,CAAC,CAAC,CAAC;IACrD,KAAK,IAAIvF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC,KAAK,IAAIgD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,SAAS,CAAChD,MAAM,EAAEmE,CAAC,EAAE,EAAE;QACzC2C,SAAS,CAAC3F,CAAC,CAAC,IAAI+B,gBAAgB,CAACiB,CAAC,CAAC,CAAChD,CAAC,CAAC,GAAG8B,MAAM,CAACkB,CAAC,CAAC;MACpD;IACF;IACAlB,MAAM,CAAC+D,MAAM,CAAC,CAAC,EAAE/D,MAAM,CAACjD,MAAM,EAAE,GAAG8G,SAAS,CAAC;EAC/C;;EAEA;EACA,MAAMG,eAAe,GAAGjE,SAAS,CAC9BpD,GAAG,CAAC,CAACmE,QAAQ,EAAET,KAAK,MAAM;IAAES,QAAQ;IAAEpB,KAAK,EAAEM,MAAM,CAACK,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CACrEC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAEsC,YAAY,CAAC,CACtBzC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACF,KAAK,GAAGG,CAAC,CAACH,KAAK,CAAC;EAEpC,MAAM8C,OAAO,GAAGa,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC,CAACsC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMzE,iBAAiB,GAAGqF,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC;;EAEpE;EACA,MAAMuC,cAAc,GAAG7E,uBAAuB,CAAC/B,IAAI,EAAE0G,OAAO,EAAExE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAMuD,iBAAiB,GAAGxD,yBAAyB,CAACC,SAAS,EAAEC,MAAM,EAAEC,gBAAgB,CAAC;EAExF,OAAO;IACLsD,MAAM,EAAE,SAAS;IACjBJ,OAAO;IACPpD,SAAS,EAAEpB,iBAAiB;IAC5B6E,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH;;AAEA;AACA,OAAO,SAASe,uBAAuBA,CAAC5H,IAAY,EAAEsG,YAAoB,GAAG,CAAC,EAAiB;EAC7F,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAMnD,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAIgG,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAGpD,SAAS,CAACqD,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAG7E,uBAAuB,CAAC/B,IAAI,EAAE0G,OAAO,EAAEpD,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMuD,iBAAiB,GAAGxD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACL4G,MAAM,EAAE,iBAAiB;MACzBJ,OAAO;MACPpD,SAAS;MACTyD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAM5B,KAAK,GAAGjF,IAAI,CAACW,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;EACxD,MAAM8C,QAAmC,GAAG,CAAC,CAAC;EAE9CF,KAAK,CAACG,OAAO,CAAElE,IAAY,IAAK;IAC9B,IAAIA,IAAI,CAACZ,MAAM,GAAG,CAAC,EAAE;MAAE;MACrB6E,QAAQ,CAACjE,IAAI,CAAC,GAAG,CAACiE,QAAQ,CAACjE,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;IAC5C;EACF,CAAC,CAAC;;EAEF;EACA,MAAM2G,cAAwB,GAAGvE,SAAS,CAACpD,GAAG,CAAEmE,QAAgB,IAAK;IACnE,MAAMyD,aAAuB,GAAGzD,QAAQ,CAAC1D,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;IAC9E,MAAMY,KAAa,GAAG6E,aAAa,CAACxG,MAAM,CAAC,CAACC,GAAW,EAAEL,IAAY,KAAKK,GAAG,IAAI4D,QAAQ,CAACjE,IAAI,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC;IACzG,OAAO+B,KAAK,GAAG6E,aAAa,CAACxH,MAAM,CAAC,CAAC;EACvC,CAAC,CAAC;;EAEF;EACA,MAAMiH,eAAe,GAAGjE,SAAS,CAC9BpD,GAAG,CAAC,CAACmE,QAAQ,EAAET,KAAK,MAAM;IAAES,QAAQ;IAAEpB,KAAK,EAAE4E,cAAc,CAACjE,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CAC7EC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACd,KAAK,GAAGa,CAAC,CAACb,KAAK,CAAC,CACjCe,KAAK,CAAC,CAAC,EAAEsC,YAAY,CAAC,CACtBzC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACF,KAAK,GAAGG,CAAC,CAACH,KAAK,CAAC;EAEpC,MAAM8C,OAAO,GAAGa,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC,CAACsC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMzE,iBAAiB,GAAGqF,eAAe,CAACrH,GAAG,CAACgE,IAAI,IAAIA,IAAI,CAACG,QAAQ,CAAC;;EAEpE;EACA,MAAMuC,cAAc,GAAG7E,uBAAuB,CAAC/B,IAAI,EAAE0G,OAAO,EAAExE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAME,gBAA4B,GAAG,EAAE;EACvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIgD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,SAAS,CAAChD,MAAM,EAAEmE,CAAC,EAAE,EAAE;MACzCjB,gBAAgB,CAAC/B,CAAC,CAAC,CAACgD,CAAC,CAAC,GAAGhD,CAAC,KAAKgD,CAAC,GAAG,CAAC,GAAGlE,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACmB,CAAC,CAAC,CAAC;IACrF;EACF;;EAEA;EACA,MAAMoC,iBAAiB,GAAGxD,yBAAyB,CAACC,SAAS,EAAEuE,cAAc,EAAErE,gBAAgB,CAAC;EAEhG,OAAO;IACLsD,MAAM,EAAE,iBAAiB;IACzBJ,OAAO;IACPpD,SAAS,EAAEpB,iBAAiB;IAC5B6E,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}