{"ast":null,"code":"// Text summarization utilities implementing TextRank and LexRank algorithms\nimport Sentiment from 'sentiment';\n// Simple sentence tokenizer\nfunction tokenizeSentences(text) {\n  return text.split(/[.!?]+/).map(s => s.trim()).filter(s => s.length > 10); // Filter out very short sentences\n}\n\n// Calculate cosine similarity between two sentences\nfunction cosineSimilarity(sent1, sent2) {\n  const words1 = sent1.toLowerCase().split(/\\s+/);\n  const words2 = sent2.toLowerCase().split(/\\s+/);\n  const allWords = Array.from(new Set([...words1, ...words2]));\n  const vector1 = allWords.map(word => words1.filter(w => w === word).length);\n  const vector2 = allWords.map(word => words2.filter(w => w === word).length);\n  const dotProduct = vector1.reduce((sum, val, i) => sum + val * vector2[i], 0);\n  const magnitude1 = Math.sqrt(vector1.reduce((sum, val) => sum + val * val, 0));\n  const magnitude2 = Math.sqrt(vector2.reduce((sum, val) => sum + val * val, 0));\n  return magnitude1 && magnitude2 ? dotProduct / (magnitude1 * magnitude2) : 0;\n}\n\n// Initialize sentiment analyzer\nconst sentiment = new Sentiment();\n\n// Calculate quality metrics for a summary\nfunction calculateQualityMetrics(originalText, summaryText, selectedSentences, allSentences) {\n  // Coverage: ratio of unique words in summary vs original\n  const originalWords = new Set(originalText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const summaryWords = new Set(summaryText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const coverage = summaryWords.size / originalWords.size;\n\n  // Coherence: average similarity between consecutive sentences in summary\n  let coherenceSum = 0;\n  for (let i = 0; i < selectedSentences.length - 1; i++) {\n    coherenceSum += cosineSimilarity(selectedSentences[i], selectedSentences[i + 1]);\n  }\n  const coherence = selectedSentences.length > 1 ? coherenceSum / (selectedSentences.length - 1) : 1;\n\n  // Diversity: ratio of unique words to total words in summary\n  const totalSummaryWords = summaryText.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const diversity = summaryWords.size / totalSummaryWords.length;\n\n  // Confidence: weighted combination of metrics\n  const confidence = coverage * 0.4 + coherence * 0.3 + diversity * 0.3;\n\n  // Sentiment analysis\n  const sentimentResult = sentiment.analyze(summaryText);\n  return {\n    coverage: Math.round(coverage * 100) / 100,\n    coherence: Math.round(coherence * 100) / 100,\n    diversity: Math.round(diversity * 100) / 100,\n    confidence: Math.round(confidence * 100) / 100,\n    sentiment: {\n      score: sentimentResult.score,\n      comparative: Math.round(sentimentResult.comparative * 100) / 100,\n      positive: sentimentResult.positive,\n      negative: sentimentResult.negative\n    }\n  };\n}\n\n// Generate visualization data\nfunction generateVisualizationData(sentences, scores, similarityMatrix) {\n  // Create sentence nodes for graph visualization\n  const sentenceGraph = sentences.map((sentence, i) => {\n    const sentimentScore = sentiment.analyze(sentence).comparative;\n    const connections = sentences.map((_, j) => {\n      var _similarityMatrix$i;\n      return {\n        target: `sentence-${j}`,\n        weight: ((_similarityMatrix$i = similarityMatrix[i]) === null || _similarityMatrix$i === void 0 ? void 0 : _similarityMatrix$i[j]) || 0\n      };\n    }).filter(conn => conn.weight > 0.1 && conn.target !== `sentence-${i}`);\n    return {\n      id: `sentence-${i}`,\n      text: sentence.slice(0, 100) + (sentence.length > 100 ? '...' : ''),\n      score: scores[i] || 0,\n      sentiment: sentimentScore,\n      connections\n    };\n  });\n\n  // Simple topic clustering based on word overlap\n  const topicClusters = generateTopicClusters(sentences);\n  return {\n    sentenceGraph,\n    topicClusters\n  };\n}\n\n// Generate topic clusters using simple k-means-like approach\nfunction generateTopicClusters(sentences) {\n  const words = sentences.flatMap(s => s.toLowerCase().match(/\\b\\w{4,}\\b/g) || []);\n  const wordFreq = {};\n  words.forEach(word => {\n    wordFreq[word] = (wordFreq[word] || 0) + 1;\n  });\n\n  // Get top keywords\n  const topWords = Object.entries(wordFreq).sort(([, a], [, b]) => b - a).slice(0, 12).map(([word]) => word);\n\n  // Create clusters based on keyword presence\n  const clusters = [];\n  const colors = ['#3B82F6', '#EF4444', '#10B981', '#F59E0B'];\n  for (let i = 0; i < Math.min(3, Math.ceil(topWords.length / 4)); i++) {\n    const clusterKeywords = topWords.slice(i * 4, (i + 1) * 4);\n    const clusterSentences = sentences.filter(sentence => clusterKeywords.some(keyword => sentence.toLowerCase().includes(keyword)));\n    if (clusterSentences.length > 0) {\n      clusters.push({\n        id: `cluster-${i}`,\n        keywords: clusterKeywords,\n        sentences: clusterSentences.map(s => s.slice(0, 80) + '...'),\n        centroid: [Math.random() * 100, Math.random() * 100],\n        // Simplified\n        color: colors[i % colors.length]\n      });\n    }\n  }\n  return clusters;\n}\n\n// TextRank implementation\nexport function textRankSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'TextRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Build similarity matrix\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      if (i === j) {\n        similarityMatrix[i][j] = 0;\n      } else {\n        similarityMatrix[i][j] = cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n  }\n\n  // PageRank algorithm\n  const scores = new Array(sentences.length).fill(1);\n  const damping = 0.85;\n  const iterations = 50;\n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = [...scores];\n    for (let i = 0; i < sentences.length; i++) {\n      let sum = 0;\n      for (let j = 0; j < sentences.length; j++) {\n        if (i !== j) {\n          const totalSim = similarityMatrix[j].reduce((a, b) => a + b, 0);\n          if (totalSim > 0) {\n            sum += similarityMatrix[j][i] / totalSim * scores[j];\n          }\n        }\n      }\n      newScores[i] = 1 - damping + damping * sum;\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: scores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  return {\n    method: 'TextRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// LexRank implementation\nexport function lexRankSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'LexRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Build similarity matrix\n  const threshold = 0.1;\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      const similarity = cosineSimilarity(sentences[i], sentences[j]);\n      similarityMatrix[i][j] = similarity > threshold ? similarity : 0;\n    }\n  }\n\n  // Normalize rows\n  for (let i = 0; i < sentences.length; i++) {\n    const rowSum = similarityMatrix[i].reduce((a, b) => a + b, 0);\n    if (rowSum > 0) {\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] /= rowSum;\n      }\n    }\n  }\n\n  // Power iteration\n  const scores = new Array(sentences.length).fill(1 / sentences.length);\n  const iterations = 50;\n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = new Array(sentences.length).fill(0);\n    for (let i = 0; i < sentences.length; i++) {\n      for (let j = 0; j < sentences.length; j++) {\n        newScores[i] += similarityMatrix[j][i] * scores[j];\n      }\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: scores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  return {\n    method: 'LexRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// Simple extractive summarization (frequency-based)\nexport function frequencyBasedSummarize(text, numSentences = 3) {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    return {\n      method: 'Frequency-Based',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n\n  // Calculate word frequencies\n  const words = text.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const wordFreq = {};\n  words.forEach(word => {\n    if (word.length > 3) {\n      // Ignore short words\n      wordFreq[word] = (wordFreq[word] || 0) + 1;\n    }\n  });\n\n  // Score sentences based on word frequencies\n  const sentenceScores = sentences.map(sentence => {\n    const sentenceWords = sentence.toLowerCase().match(/\\b\\w+\\b/g) || [];\n    const score = sentenceWords.reduce((sum, word) => sum + (wordFreq[word] || 0), 0);\n    return score / sentenceWords.length; // Normalize by sentence length\n  });\n\n  // Get top sentences\n  const rankedSentences = sentences.map((sentence, index) => ({\n    sentence,\n    score: sentenceScores[index],\n    index\n  })).sort((a, b) => b.score - a.score).slice(0, numSentences).sort((a, b) => a.index - b.index);\n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n\n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n\n  // Create a simple similarity matrix for visualization (based on word overlap)\n  const similarityMatrix = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n    }\n  }\n\n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n  return {\n    method: 'Frequency-Based',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}","map":{"version":3,"names":["Sentiment","tokenizeSentences","text","split","map","s","trim","filter","length","cosineSimilarity","sent1","sent2","words1","toLowerCase","words2","allWords","Array","from","Set","vector1","word","w","vector2","dotProduct","reduce","sum","val","i","magnitude1","Math","sqrt","magnitude2","sentiment","calculateQualityMetrics","originalText","summaryText","selectedSentences","allSentences","originalWords","match","summaryWords","coverage","size","coherenceSum","coherence","totalSummaryWords","diversity","confidence","sentimentResult","analyze","round","score","comparative","positive","negative","generateVisualizationData","sentences","scores","similarityMatrix","sentenceGraph","sentence","sentimentScore","connections","_","j","_similarityMatrix$i","target","weight","conn","id","slice","topicClusters","generateTopicClusters","words","flatMap","wordFreq","forEach","topWords","Object","entries","sort","a","b","clusters","colors","min","ceil","clusterKeywords","clusterSentences","some","keyword","includes","push","keywords","centroid","random","color","textRankSummarize","numSentences","startTime","Date","now","summary","join","qualityMetrics","visualizationData","method","processingTime","fill","damping","iterations","iter","newScores","totalSim","splice","rankedSentences","index","item","lexRankSummarize","threshold","similarity","rowSum","frequencyBasedSummarize","sentenceScores","sentenceWords"],"sources":["/Users/averyreyna/Codebases/rerank/src/utils/textSummarization.ts"],"sourcesContent":["// Text summarization utilities implementing TextRank and LexRank algorithms\nimport Sentiment from 'sentiment';\n\nexport interface QualityMetrics {\n  coverage: number; // 0-1, how much of the original text is represented\n  coherence: number; // 0-1, how well sentences flow together\n  diversity: number; // 0-1, how diverse the vocabulary is\n  confidence: number; // 0-1, overall confidence in the summary\n  sentiment: {\n    score: number;\n    comparative: number;\n    positive: string[];\n    negative: string[];\n  };\n}\n\nexport interface SentenceNode {\n  id: string;\n  text: string;\n  score: number;\n  sentiment: number;\n  connections: { target: string; weight: number }[];\n  position?: { x: number; y: number };\n}\n\nexport interface TopicCluster {\n  id: string;\n  keywords: string[];\n  sentences: string[];\n  centroid: number[];\n  color: string;\n}\n\nexport interface SummaryResult {\n  method: string;\n  summary: string;\n  sentences: string[];\n  processingTime: number;\n  qualityMetrics: QualityMetrics;\n  visualizationData: {\n    sentenceGraph: SentenceNode[];\n    topicClusters: TopicCluster[];\n  };\n}\n\n// Simple sentence tokenizer\nfunction tokenizeSentences(text: string): string[] {\n  return text\n    .split(/[.!?]+/)\n    .map(s => s.trim())\n    .filter(s => s.length > 10); // Filter out very short sentences\n}\n\n// Calculate cosine similarity between two sentences\nfunction cosineSimilarity(sent1: string, sent2: string): number {\n  const words1 = sent1.toLowerCase().split(/\\s+/);\n  const words2 = sent2.toLowerCase().split(/\\s+/);\n  \n  const allWords = Array.from(new Set([...words1, ...words2]));\n  \n  const vector1 = allWords.map(word => words1.filter(w => w === word).length);\n  const vector2 = allWords.map(word => words2.filter(w => w === word).length);\n  \n  const dotProduct = vector1.reduce((sum, val, i) => sum + val * vector2[i], 0);\n  const magnitude1 = Math.sqrt(vector1.reduce((sum, val) => sum + val * val, 0));\n  const magnitude2 = Math.sqrt(vector2.reduce((sum, val) => sum + val * val, 0));\n  \n  return magnitude1 && magnitude2 ? dotProduct / (magnitude1 * magnitude2) : 0;\n}\n\n// Initialize sentiment analyzer\nconst sentiment = new Sentiment();\n\n// Calculate quality metrics for a summary\nfunction calculateQualityMetrics(\n  originalText: string, \n  summaryText: string, \n  selectedSentences: string[],\n  allSentences: string[]\n): QualityMetrics {\n  // Coverage: ratio of unique words in summary vs original\n  const originalWords = new Set(originalText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const summaryWords = new Set(summaryText.toLowerCase().match(/\\b\\w+\\b/g) || []);\n  const coverage = summaryWords.size / originalWords.size;\n\n  // Coherence: average similarity between consecutive sentences in summary\n  let coherenceSum = 0;\n  for (let i = 0; i < selectedSentences.length - 1; i++) {\n    coherenceSum += cosineSimilarity(selectedSentences[i], selectedSentences[i + 1]);\n  }\n  const coherence = selectedSentences.length > 1 ? coherenceSum / (selectedSentences.length - 1) : 1;\n\n  // Diversity: ratio of unique words to total words in summary\n  const totalSummaryWords = summaryText.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const diversity = summaryWords.size / totalSummaryWords.length;\n\n  // Confidence: weighted combination of metrics\n  const confidence = (coverage * 0.4 + coherence * 0.3 + diversity * 0.3);\n\n  // Sentiment analysis\n  const sentimentResult = sentiment.analyze(summaryText);\n\n  return {\n    coverage: Math.round(coverage * 100) / 100,\n    coherence: Math.round(coherence * 100) / 100,\n    diversity: Math.round(diversity * 100) / 100,\n    confidence: Math.round(confidence * 100) / 100,\n    sentiment: {\n      score: sentimentResult.score,\n      comparative: Math.round(sentimentResult.comparative * 100) / 100,\n      positive: sentimentResult.positive,\n      negative: sentimentResult.negative\n    }\n  };\n}\n\n// Generate visualization data\nfunction generateVisualizationData(\n  sentences: string[], \n  scores: number[], \n  similarityMatrix: number[][]\n): { sentenceGraph: SentenceNode[]; topicClusters: TopicCluster[] } {\n  // Create sentence nodes for graph visualization\n  const sentenceGraph: SentenceNode[] = sentences.map((sentence, i) => {\n    const sentimentScore = sentiment.analyze(sentence).comparative;\n    const connections = sentences.map((_, j) => ({\n      target: `sentence-${j}`,\n      weight: similarityMatrix[i]?.[j] || 0\n    })).filter(conn => conn.weight > 0.1 && conn.target !== `sentence-${i}`);\n\n    return {\n      id: `sentence-${i}`,\n      text: sentence.slice(0, 100) + (sentence.length > 100 ? '...' : ''),\n      score: scores[i] || 0,\n      sentiment: sentimentScore,\n      connections\n    };\n  });\n\n  // Simple topic clustering based on word overlap\n  const topicClusters = generateTopicClusters(sentences);\n\n  return { sentenceGraph, topicClusters };\n}\n\n// Generate topic clusters using simple k-means-like approach\nfunction generateTopicClusters(sentences: string[]): TopicCluster[] {\n  const words = sentences.flatMap(s => \n    s.toLowerCase().match(/\\b\\w{4,}\\b/g) || []\n  );\n  \n  const wordFreq: { [key: string]: number } = {};\n  words.forEach(word => {\n    wordFreq[word] = (wordFreq[word] || 0) + 1;\n  });\n\n  // Get top keywords\n  const topWords = Object.entries(wordFreq)\n    .sort(([,a], [,b]) => b - a)\n    .slice(0, 12)\n    .map(([word]) => word);\n\n  // Create clusters based on keyword presence\n  const clusters: TopicCluster[] = [];\n  const colors = ['#3B82F6', '#EF4444', '#10B981', '#F59E0B'];\n  \n  for (let i = 0; i < Math.min(3, Math.ceil(topWords.length / 4)); i++) {\n    const clusterKeywords = topWords.slice(i * 4, (i + 1) * 4);\n    const clusterSentences = sentences.filter(sentence => \n      clusterKeywords.some(keyword => \n        sentence.toLowerCase().includes(keyword)\n      )\n    );\n\n    if (clusterSentences.length > 0) {\n      clusters.push({\n        id: `cluster-${i}`,\n        keywords: clusterKeywords,\n        sentences: clusterSentences.map(s => s.slice(0, 80) + '...'),\n        centroid: [Math.random() * 100, Math.random() * 100], // Simplified\n        color: colors[i % colors.length]\n      });\n    }\n  }\n\n  return clusters;\n}\n\n// TextRank implementation\nexport function textRankSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'TextRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Build similarity matrix\n  const similarityMatrix: number[][] = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      if (i === j) {\n        similarityMatrix[i][j] = 0;\n      } else {\n        similarityMatrix[i][j] = cosineSimilarity(sentences[i], sentences[j]);\n      }\n    }\n  }\n  \n  // PageRank algorithm\n  const scores = new Array(sentences.length).fill(1);\n  const damping = 0.85;\n  const iterations = 50;\n  \n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = [...scores];\n    for (let i = 0; i < sentences.length; i++) {\n      let sum = 0;\n      for (let j = 0; j < sentences.length; j++) {\n        if (i !== j) {\n          const totalSim = similarityMatrix[j].reduce((a, b) => a + b, 0);\n          if (totalSim > 0) {\n            sum += (similarityMatrix[j][i] / totalSim) * scores[j];\n          }\n        }\n      }\n      newScores[i] = (1 - damping) + damping * sum;\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: scores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  \n  return {\n    method: 'TextRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// LexRank implementation\nexport function lexRankSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'LexRank',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Build similarity matrix\n  const threshold = 0.1;\n  const similarityMatrix: number[][] = [];\n  \n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      const similarity = cosineSimilarity(sentences[i], sentences[j]);\n      similarityMatrix[i][j] = similarity > threshold ? similarity : 0;\n    }\n  }\n  \n  // Normalize rows\n  for (let i = 0; i < sentences.length; i++) {\n    const rowSum = similarityMatrix[i].reduce((a, b) => a + b, 0);\n    if (rowSum > 0) {\n      for (let j = 0; j < sentences.length; j++) {\n        similarityMatrix[i][j] /= rowSum;\n      }\n    }\n  }\n  \n  // Power iteration\n  const scores = new Array(sentences.length).fill(1 / sentences.length);\n  const iterations = 50;\n  \n  for (let iter = 0; iter < iterations; iter++) {\n    const newScores = new Array(sentences.length).fill(0);\n    for (let i = 0; i < sentences.length; i++) {\n      for (let j = 0; j < sentences.length; j++) {\n        newScores[i] += similarityMatrix[j][i] * scores[j];\n      }\n    }\n    scores.splice(0, scores.length, ...newScores);\n  }\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: scores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, scores, similarityMatrix);\n  \n  return {\n    method: 'LexRank',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n\n// Simple extractive summarization (frequency-based)\nexport function frequencyBasedSummarize(text: string, numSentences: number = 3): SummaryResult {\n  const startTime = Date.now();\n  const sentences = tokenizeSentences(text);\n  \n  if (sentences.length <= numSentences) {\n    const summary = sentences.join('. ') + '.';\n    const qualityMetrics = calculateQualityMetrics(text, summary, sentences, sentences);\n    const visualizationData = generateVisualizationData(sentences, sentences.map(() => 1), []);\n    \n    return {\n      method: 'Frequency-Based',\n      summary,\n      sentences,\n      processingTime: Date.now() - startTime,\n      qualityMetrics,\n      visualizationData\n    };\n  }\n  \n  // Calculate word frequencies\n  const words = text.toLowerCase().match(/\\b\\w+\\b/g) || [];\n  const wordFreq: { [key: string]: number } = {};\n  \n  words.forEach((word: string) => {\n    if (word.length > 3) { // Ignore short words\n      wordFreq[word] = (wordFreq[word] || 0) + 1;\n    }\n  });\n  \n  // Score sentences based on word frequencies\n  const sentenceScores: number[] = sentences.map((sentence: string) => {\n    const sentenceWords: string[] = sentence.toLowerCase().match(/\\b\\w+\\b/g) || [];\n    const score: number = sentenceWords.reduce((sum: number, word: string) => sum + (wordFreq[word] || 0), 0);\n    return score / sentenceWords.length; // Normalize by sentence length\n  });\n  \n  // Get top sentences\n  const rankedSentences = sentences\n    .map((sentence, index) => ({ sentence, score: sentenceScores[index], index }))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, numSentences)\n    .sort((a, b) => a.index - b.index);\n  \n  const summary = rankedSentences.map(item => item.sentence).join('. ') + '.';\n  const selectedSentences = rankedSentences.map(item => item.sentence);\n  \n  // Calculate quality metrics\n  const qualityMetrics = calculateQualityMetrics(text, summary, selectedSentences, sentences);\n  \n  // Create a simple similarity matrix for visualization (based on word overlap)\n  const similarityMatrix: number[][] = [];\n  for (let i = 0; i < sentences.length; i++) {\n    similarityMatrix[i] = [];\n    for (let j = 0; j < sentences.length; j++) {\n      similarityMatrix[i][j] = i === j ? 0 : cosineSimilarity(sentences[i], sentences[j]);\n    }\n  }\n  \n  // Generate visualization data\n  const visualizationData = generateVisualizationData(sentences, sentenceScores, similarityMatrix);\n  \n  return {\n    method: 'Frequency-Based',\n    summary,\n    sentences: selectedSentences,\n    processingTime: Date.now() - startTime,\n    qualityMetrics,\n    visualizationData\n  };\n}\n"],"mappings":"AAAA;AACA,OAAOA,SAAS,MAAM,WAAW;AA4CjC;AACA,SAASC,iBAAiBA,CAACC,IAAY,EAAY;EACjD,OAAOA,IAAI,CACRC,KAAK,CAAC,QAAQ,CAAC,CACfC,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACC,IAAI,CAAC,CAAC,CAAC,CAClBC,MAAM,CAACF,CAAC,IAAIA,CAAC,CAACG,MAAM,GAAG,EAAE,CAAC,CAAC,CAAC;AACjC;;AAEA;AACA,SAASC,gBAAgBA,CAACC,KAAa,EAAEC,KAAa,EAAU;EAC9D,MAAMC,MAAM,GAAGF,KAAK,CAACG,WAAW,CAAC,CAAC,CAACV,KAAK,CAAC,KAAK,CAAC;EAC/C,MAAMW,MAAM,GAAGH,KAAK,CAACE,WAAW,CAAC,CAAC,CAACV,KAAK,CAAC,KAAK,CAAC;EAE/C,MAAMY,QAAQ,GAAGC,KAAK,CAACC,IAAI,CAAC,IAAIC,GAAG,CAAC,CAAC,GAAGN,MAAM,EAAE,GAAGE,MAAM,CAAC,CAAC,CAAC;EAE5D,MAAMK,OAAO,GAAGJ,QAAQ,CAACX,GAAG,CAACgB,IAAI,IAAIR,MAAM,CAACL,MAAM,CAACc,CAAC,IAAIA,CAAC,KAAKD,IAAI,CAAC,CAACZ,MAAM,CAAC;EAC3E,MAAMc,OAAO,GAAGP,QAAQ,CAACX,GAAG,CAACgB,IAAI,IAAIN,MAAM,CAACP,MAAM,CAACc,CAAC,IAAIA,CAAC,KAAKD,IAAI,CAAC,CAACZ,MAAM,CAAC;EAE3E,MAAMe,UAAU,GAAGJ,OAAO,CAACK,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,EAAEC,CAAC,KAAKF,GAAG,GAAGC,GAAG,GAAGJ,OAAO,CAACK,CAAC,CAAC,EAAE,CAAC,CAAC;EAC7E,MAAMC,UAAU,GAAGC,IAAI,CAACC,IAAI,CAACX,OAAO,CAACK,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAGC,GAAG,GAAGA,GAAG,EAAE,CAAC,CAAC,CAAC;EAC9E,MAAMK,UAAU,GAAGF,IAAI,CAACC,IAAI,CAACR,OAAO,CAACE,MAAM,CAAC,CAACC,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAGC,GAAG,GAAGA,GAAG,EAAE,CAAC,CAAC,CAAC;EAE9E,OAAOE,UAAU,IAAIG,UAAU,GAAGR,UAAU,IAAIK,UAAU,GAAGG,UAAU,CAAC,GAAG,CAAC;AAC9E;;AAEA;AACA,MAAMC,SAAS,GAAG,IAAIhC,SAAS,CAAC,CAAC;;AAEjC;AACA,SAASiC,uBAAuBA,CAC9BC,YAAoB,EACpBC,WAAmB,EACnBC,iBAA2B,EAC3BC,YAAsB,EACN;EAChB;EACA,MAAMC,aAAa,GAAG,IAAIpB,GAAG,CAACgB,YAAY,CAACrB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC;EACjF,MAAMC,YAAY,GAAG,IAAItB,GAAG,CAACiB,WAAW,CAACtB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC;EAC/E,MAAME,QAAQ,GAAGD,YAAY,CAACE,IAAI,GAAGJ,aAAa,CAACI,IAAI;;EAEvD;EACA,IAAIC,YAAY,GAAG,CAAC;EACpB,KAAK,IAAIhB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGS,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,EAAEmB,CAAC,EAAE,EAAE;IACrDgB,YAAY,IAAIlC,gBAAgB,CAAC2B,iBAAiB,CAACT,CAAC,CAAC,EAAES,iBAAiB,CAACT,CAAC,GAAG,CAAC,CAAC,CAAC;EAClF;EACA,MAAMiB,SAAS,GAAGR,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,GAAGmC,YAAY,IAAIP,iBAAiB,CAAC5B,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC;;EAElG;EACA,MAAMqC,iBAAiB,GAAGV,WAAW,CAACtB,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;EAC3E,MAAMO,SAAS,GAAGN,YAAY,CAACE,IAAI,GAAGG,iBAAiB,CAACrC,MAAM;;EAE9D;EACA,MAAMuC,UAAU,GAAIN,QAAQ,GAAG,GAAG,GAAGG,SAAS,GAAG,GAAG,GAAGE,SAAS,GAAG,GAAI;;EAEvE;EACA,MAAME,eAAe,GAAGhB,SAAS,CAACiB,OAAO,CAACd,WAAW,CAAC;EAEtD,OAAO;IACLM,QAAQ,EAAEZ,IAAI,CAACqB,KAAK,CAACT,QAAQ,GAAG,GAAG,CAAC,GAAG,GAAG;IAC1CG,SAAS,EAAEf,IAAI,CAACqB,KAAK,CAACN,SAAS,GAAG,GAAG,CAAC,GAAG,GAAG;IAC5CE,SAAS,EAAEjB,IAAI,CAACqB,KAAK,CAACJ,SAAS,GAAG,GAAG,CAAC,GAAG,GAAG;IAC5CC,UAAU,EAAElB,IAAI,CAACqB,KAAK,CAACH,UAAU,GAAG,GAAG,CAAC,GAAG,GAAG;IAC9Cf,SAAS,EAAE;MACTmB,KAAK,EAAEH,eAAe,CAACG,KAAK;MAC5BC,WAAW,EAAEvB,IAAI,CAACqB,KAAK,CAACF,eAAe,CAACI,WAAW,GAAG,GAAG,CAAC,GAAG,GAAG;MAChEC,QAAQ,EAAEL,eAAe,CAACK,QAAQ;MAClCC,QAAQ,EAAEN,eAAe,CAACM;IAC5B;EACF,CAAC;AACH;;AAEA;AACA,SAASC,yBAAyBA,CAChCC,SAAmB,EACnBC,MAAgB,EAChBC,gBAA4B,EACsC;EAClE;EACA,MAAMC,aAA6B,GAAGH,SAAS,CAACpD,GAAG,CAAC,CAACwD,QAAQ,EAAEjC,CAAC,KAAK;IACnE,MAAMkC,cAAc,GAAG7B,SAAS,CAACiB,OAAO,CAACW,QAAQ,CAAC,CAACR,WAAW;IAC9D,MAAMU,WAAW,GAAGN,SAAS,CAACpD,GAAG,CAAC,CAAC2D,CAAC,EAAEC,CAAC;MAAA,IAAAC,mBAAA;MAAA,OAAM;QAC3CC,MAAM,EAAE,YAAYF,CAAC,EAAE;QACvBG,MAAM,EAAE,EAAAF,mBAAA,GAAAP,gBAAgB,CAAC/B,CAAC,CAAC,cAAAsC,mBAAA,uBAAnBA,mBAAA,CAAsBD,CAAC,CAAC,KAAI;MACtC,CAAC;IAAA,CAAC,CAAC,CAACzD,MAAM,CAAC6D,IAAI,IAAIA,IAAI,CAACD,MAAM,GAAG,GAAG,IAAIC,IAAI,CAACF,MAAM,KAAK,YAAYvC,CAAC,EAAE,CAAC;IAExE,OAAO;MACL0C,EAAE,EAAE,YAAY1C,CAAC,EAAE;MACnBzB,IAAI,EAAE0D,QAAQ,CAACU,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,IAAIV,QAAQ,CAACpD,MAAM,GAAG,GAAG,GAAG,KAAK,GAAG,EAAE,CAAC;MACnE2C,KAAK,EAAEM,MAAM,CAAC9B,CAAC,CAAC,IAAI,CAAC;MACrBK,SAAS,EAAE6B,cAAc;MACzBC;IACF,CAAC;EACH,CAAC,CAAC;;EAEF;EACA,MAAMS,aAAa,GAAGC,qBAAqB,CAAChB,SAAS,CAAC;EAEtD,OAAO;IAAEG,aAAa;IAAEY;EAAc,CAAC;AACzC;;AAEA;AACA,SAASC,qBAAqBA,CAAChB,SAAmB,EAAkB;EAClE,MAAMiB,KAAK,GAAGjB,SAAS,CAACkB,OAAO,CAACrE,CAAC,IAC/BA,CAAC,CAACQ,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,aAAa,CAAC,IAAI,EAC1C,CAAC;EAED,MAAMoC,QAAmC,GAAG,CAAC,CAAC;EAC9CF,KAAK,CAACG,OAAO,CAACxD,IAAI,IAAI;IACpBuD,QAAQ,CAACvD,IAAI,CAAC,GAAG,CAACuD,QAAQ,CAACvD,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;EAC5C,CAAC,CAAC;;EAEF;EACA,MAAMyD,QAAQ,GAAGC,MAAM,CAACC,OAAO,CAACJ,QAAQ,CAAC,CACtCK,IAAI,CAAC,CAAC,GAAEC,CAAC,CAAC,EAAE,GAAEC,CAAC,CAAC,KAAKA,CAAC,GAAGD,CAAC,CAAC,CAC3BX,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,CACZlE,GAAG,CAAC,CAAC,CAACgB,IAAI,CAAC,KAAKA,IAAI,CAAC;;EAExB;EACA,MAAM+D,QAAwB,GAAG,EAAE;EACnC,MAAMC,MAAM,GAAG,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;EAE3D,KAAK,IAAIzD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGE,IAAI,CAACwD,GAAG,CAAC,CAAC,EAAExD,IAAI,CAACyD,IAAI,CAACT,QAAQ,CAACrE,MAAM,GAAG,CAAC,CAAC,CAAC,EAAEmB,CAAC,EAAE,EAAE;IACpE,MAAM4D,eAAe,GAAGV,QAAQ,CAACP,KAAK,CAAC3C,CAAC,GAAG,CAAC,EAAE,CAACA,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IAC1D,MAAM6D,gBAAgB,GAAGhC,SAAS,CAACjD,MAAM,CAACqD,QAAQ,IAChD2B,eAAe,CAACE,IAAI,CAACC,OAAO,IAC1B9B,QAAQ,CAAC/C,WAAW,CAAC,CAAC,CAAC8E,QAAQ,CAACD,OAAO,CACzC,CACF,CAAC;IAED,IAAIF,gBAAgB,CAAChF,MAAM,GAAG,CAAC,EAAE;MAC/B2E,QAAQ,CAACS,IAAI,CAAC;QACZvB,EAAE,EAAE,WAAW1C,CAAC,EAAE;QAClBkE,QAAQ,EAAEN,eAAe;QACzB/B,SAAS,EAAEgC,gBAAgB,CAACpF,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACiE,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,GAAG,KAAK,CAAC;QAC5DwB,QAAQ,EAAE,CAACjE,IAAI,CAACkE,MAAM,CAAC,CAAC,GAAG,GAAG,EAAElE,IAAI,CAACkE,MAAM,CAAC,CAAC,GAAG,GAAG,CAAC;QAAE;QACtDC,KAAK,EAAEZ,MAAM,CAACzD,CAAC,GAAGyD,MAAM,CAAC5E,MAAM;MACjC,CAAC,CAAC;IACJ;EACF;EAEA,OAAO2E,QAAQ;AACjB;;AAEA;AACA,OAAO,SAASc,iBAAiBA,CAAC/F,IAAY,EAAEgG,YAAoB,GAAG,CAAC,EAAiB;EACvF,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAM7C,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAI0F,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAG9C,SAAS,CAAC+C,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAGvE,uBAAuB,CAAC/B,IAAI,EAAEoG,OAAO,EAAE9C,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMiD,iBAAiB,GAAGlD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACLsG,MAAM,EAAE,UAAU;MAClBJ,OAAO;MACP9C,SAAS;MACTmD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAM/C,gBAA4B,GAAG,EAAE;EACvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIqC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGR,SAAS,CAAChD,MAAM,EAAEwD,CAAC,EAAE,EAAE;MACzC,IAAIrC,CAAC,KAAKqC,CAAC,EAAE;QACXN,gBAAgB,CAAC/B,CAAC,CAAC,CAACqC,CAAC,CAAC,GAAG,CAAC;MAC5B,CAAC,MAAM;QACLN,gBAAgB,CAAC/B,CAAC,CAAC,CAACqC,CAAC,CAAC,GAAGvD,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACQ,CAAC,CAAC,CAAC;MACvE;IACF;EACF;;EAEA;EACA,MAAMP,MAAM,GAAG,IAAIzC,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAACoG,IAAI,CAAC,CAAC,CAAC;EAClD,MAAMC,OAAO,GAAG,IAAI;EACpB,MAAMC,UAAU,GAAG,EAAE;EAErB,KAAK,IAAIC,IAAI,GAAG,CAAC,EAAEA,IAAI,GAAGD,UAAU,EAAEC,IAAI,EAAE,EAAE;IAC5C,MAAMC,SAAS,GAAG,CAAC,GAAGvD,MAAM,CAAC;IAC7B,KAAK,IAAI9B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC,IAAIF,GAAG,GAAG,CAAC;MACX,KAAK,IAAIuC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGR,SAAS,CAAChD,MAAM,EAAEwD,CAAC,EAAE,EAAE;QACzC,IAAIrC,CAAC,KAAKqC,CAAC,EAAE;UACX,MAAMiD,QAAQ,GAAGvD,gBAAgB,CAACM,CAAC,CAAC,CAACxC,MAAM,CAAC,CAACyD,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC;UAC/D,IAAI+B,QAAQ,GAAG,CAAC,EAAE;YAChBxF,GAAG,IAAKiC,gBAAgB,CAACM,CAAC,CAAC,CAACrC,CAAC,CAAC,GAAGsF,QAAQ,GAAIxD,MAAM,CAACO,CAAC,CAAC;UACxD;QACF;MACF;MACAgD,SAAS,CAACrF,CAAC,CAAC,GAAI,CAAC,GAAGkF,OAAO,GAAIA,OAAO,GAAGpF,GAAG;IAC9C;IACAgC,MAAM,CAACyD,MAAM,CAAC,CAAC,EAAEzD,MAAM,CAACjD,MAAM,EAAE,GAAGwG,SAAS,CAAC;EAC/C;;EAEA;EACA,MAAMG,eAAe,GAAG3D,SAAS,CAC9BpD,GAAG,CAAC,CAACwD,QAAQ,EAAEwD,KAAK,MAAM;IAAExD,QAAQ;IAAET,KAAK,EAAEM,MAAM,CAAC2D,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CACrEpC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAAC/B,KAAK,GAAG8B,CAAC,CAAC9B,KAAK,CAAC,CACjCmB,KAAK,CAAC,CAAC,EAAE4B,YAAY,CAAC,CACtBlB,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACmC,KAAK,GAAGlC,CAAC,CAACkC,KAAK,CAAC;EAEpC,MAAMd,OAAO,GAAGa,eAAe,CAAC/G,GAAG,CAACiH,IAAI,IAAIA,IAAI,CAACzD,QAAQ,CAAC,CAAC2C,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMnE,iBAAiB,GAAG+E,eAAe,CAAC/G,GAAG,CAACiH,IAAI,IAAIA,IAAI,CAACzD,QAAQ,CAAC;;EAEpE;EACA,MAAM4C,cAAc,GAAGvE,uBAAuB,CAAC/B,IAAI,EAAEoG,OAAO,EAAElE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAMiD,iBAAiB,GAAGlD,yBAAyB,CAACC,SAAS,EAAEC,MAAM,EAAEC,gBAAgB,CAAC;EAExF,OAAO;IACLgD,MAAM,EAAE,UAAU;IAClBJ,OAAO;IACP9C,SAAS,EAAEpB,iBAAiB;IAC5BuE,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH;;AAEA;AACA,OAAO,SAASa,gBAAgBA,CAACpH,IAAY,EAAEgG,YAAoB,GAAG,CAAC,EAAiB;EACtF,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAM7C,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAI0F,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAG9C,SAAS,CAAC+C,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAGvE,uBAAuB,CAAC/B,IAAI,EAAEoG,OAAO,EAAE9C,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMiD,iBAAiB,GAAGlD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACLsG,MAAM,EAAE,SAAS;MACjBJ,OAAO;MACP9C,SAAS;MACTmD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAMc,SAAS,GAAG,GAAG;EACrB,MAAM7D,gBAA4B,GAAG,EAAE;EAEvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIqC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGR,SAAS,CAAChD,MAAM,EAAEwD,CAAC,EAAE,EAAE;MACzC,MAAMwD,UAAU,GAAG/G,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACQ,CAAC,CAAC,CAAC;MAC/DN,gBAAgB,CAAC/B,CAAC,CAAC,CAACqC,CAAC,CAAC,GAAGwD,UAAU,GAAGD,SAAS,GAAGC,UAAU,GAAG,CAAC;IAClE;EACF;;EAEA;EACA,KAAK,IAAI7F,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC,MAAM8F,MAAM,GAAG/D,gBAAgB,CAAC/B,CAAC,CAAC,CAACH,MAAM,CAAC,CAACyD,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC;IAC7D,IAAIuC,MAAM,GAAG,CAAC,EAAE;MACd,KAAK,IAAIzD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGR,SAAS,CAAChD,MAAM,EAAEwD,CAAC,EAAE,EAAE;QACzCN,gBAAgB,CAAC/B,CAAC,CAAC,CAACqC,CAAC,CAAC,IAAIyD,MAAM;MAClC;IACF;EACF;;EAEA;EACA,MAAMhE,MAAM,GAAG,IAAIzC,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAACoG,IAAI,CAAC,CAAC,GAAGpD,SAAS,CAAChD,MAAM,CAAC;EACrE,MAAMsG,UAAU,GAAG,EAAE;EAErB,KAAK,IAAIC,IAAI,GAAG,CAAC,EAAEA,IAAI,GAAGD,UAAU,EAAEC,IAAI,EAAE,EAAE;IAC5C,MAAMC,SAAS,GAAG,IAAIhG,KAAK,CAACwC,SAAS,CAAChD,MAAM,CAAC,CAACoG,IAAI,CAAC,CAAC,CAAC;IACrD,KAAK,IAAIjF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;MACzC,KAAK,IAAIqC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGR,SAAS,CAAChD,MAAM,EAAEwD,CAAC,EAAE,EAAE;QACzCgD,SAAS,CAACrF,CAAC,CAAC,IAAI+B,gBAAgB,CAACM,CAAC,CAAC,CAACrC,CAAC,CAAC,GAAG8B,MAAM,CAACO,CAAC,CAAC;MACpD;IACF;IACAP,MAAM,CAACyD,MAAM,CAAC,CAAC,EAAEzD,MAAM,CAACjD,MAAM,EAAE,GAAGwG,SAAS,CAAC;EAC/C;;EAEA;EACA,MAAMG,eAAe,GAAG3D,SAAS,CAC9BpD,GAAG,CAAC,CAACwD,QAAQ,EAAEwD,KAAK,MAAM;IAAExD,QAAQ;IAAET,KAAK,EAAEM,MAAM,CAAC2D,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CACrEpC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAAC/B,KAAK,GAAG8B,CAAC,CAAC9B,KAAK,CAAC,CACjCmB,KAAK,CAAC,CAAC,EAAE4B,YAAY,CAAC,CACtBlB,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACmC,KAAK,GAAGlC,CAAC,CAACkC,KAAK,CAAC;EAEpC,MAAMd,OAAO,GAAGa,eAAe,CAAC/G,GAAG,CAACiH,IAAI,IAAIA,IAAI,CAACzD,QAAQ,CAAC,CAAC2C,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMnE,iBAAiB,GAAG+E,eAAe,CAAC/G,GAAG,CAACiH,IAAI,IAAIA,IAAI,CAACzD,QAAQ,CAAC;;EAEpE;EACA,MAAM4C,cAAc,GAAGvE,uBAAuB,CAAC/B,IAAI,EAAEoG,OAAO,EAAElE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAMiD,iBAAiB,GAAGlD,yBAAyB,CAACC,SAAS,EAAEC,MAAM,EAAEC,gBAAgB,CAAC;EAExF,OAAO;IACLgD,MAAM,EAAE,SAAS;IACjBJ,OAAO;IACP9C,SAAS,EAAEpB,iBAAiB;IAC5BuE,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH;;AAEA;AACA,OAAO,SAASiB,uBAAuBA,CAACxH,IAAY,EAAEgG,YAAoB,GAAG,CAAC,EAAiB;EAC7F,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAC5B,MAAM7C,SAAS,GAAGvD,iBAAiB,CAACC,IAAI,CAAC;EAEzC,IAAIsD,SAAS,CAAChD,MAAM,IAAI0F,YAAY,EAAE;IACpC,MAAMI,OAAO,GAAG9C,SAAS,CAAC+C,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;IAC1C,MAAMC,cAAc,GAAGvE,uBAAuB,CAAC/B,IAAI,EAAEoG,OAAO,EAAE9C,SAAS,EAAEA,SAAS,CAAC;IACnF,MAAMiD,iBAAiB,GAAGlD,yBAAyB,CAACC,SAAS,EAAEA,SAAS,CAACpD,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE,EAAE,CAAC;IAE1F,OAAO;MACLsG,MAAM,EAAE,iBAAiB;MACzBJ,OAAO;MACP9C,SAAS;MACTmD,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;MACtCK,cAAc;MACdC;IACF,CAAC;EACH;;EAEA;EACA,MAAMhC,KAAK,GAAGvE,IAAI,CAACW,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;EACxD,MAAMoC,QAAmC,GAAG,CAAC,CAAC;EAE9CF,KAAK,CAACG,OAAO,CAAExD,IAAY,IAAK;IAC9B,IAAIA,IAAI,CAACZ,MAAM,GAAG,CAAC,EAAE;MAAE;MACrBmE,QAAQ,CAACvD,IAAI,CAAC,GAAG,CAACuD,QAAQ,CAACvD,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;IAC5C;EACF,CAAC,CAAC;;EAEF;EACA,MAAMuG,cAAwB,GAAGnE,SAAS,CAACpD,GAAG,CAAEwD,QAAgB,IAAK;IACnE,MAAMgE,aAAuB,GAAGhE,QAAQ,CAAC/C,WAAW,CAAC,CAAC,CAAC0B,KAAK,CAAC,UAAU,CAAC,IAAI,EAAE;IAC9E,MAAMY,KAAa,GAAGyE,aAAa,CAACpG,MAAM,CAAC,CAACC,GAAW,EAAEL,IAAY,KAAKK,GAAG,IAAIkD,QAAQ,CAACvD,IAAI,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC;IACzG,OAAO+B,KAAK,GAAGyE,aAAa,CAACpH,MAAM,CAAC,CAAC;EACvC,CAAC,CAAC;;EAEF;EACA,MAAM2G,eAAe,GAAG3D,SAAS,CAC9BpD,GAAG,CAAC,CAACwD,QAAQ,EAAEwD,KAAK,MAAM;IAAExD,QAAQ;IAAET,KAAK,EAAEwE,cAAc,CAACP,KAAK,CAAC;IAAEA;EAAM,CAAC,CAAC,CAAC,CAC7EpC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAAC/B,KAAK,GAAG8B,CAAC,CAAC9B,KAAK,CAAC,CACjCmB,KAAK,CAAC,CAAC,EAAE4B,YAAY,CAAC,CACtBlB,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAACmC,KAAK,GAAGlC,CAAC,CAACkC,KAAK,CAAC;EAEpC,MAAMd,OAAO,GAAGa,eAAe,CAAC/G,GAAG,CAACiH,IAAI,IAAIA,IAAI,CAACzD,QAAQ,CAAC,CAAC2C,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG;EAC3E,MAAMnE,iBAAiB,GAAG+E,eAAe,CAAC/G,GAAG,CAACiH,IAAI,IAAIA,IAAI,CAACzD,QAAQ,CAAC;;EAEpE;EACA,MAAM4C,cAAc,GAAGvE,uBAAuB,CAAC/B,IAAI,EAAEoG,OAAO,EAAElE,iBAAiB,EAAEoB,SAAS,CAAC;;EAE3F;EACA,MAAME,gBAA4B,GAAG,EAAE;EACvC,KAAK,IAAI/B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,SAAS,CAAChD,MAAM,EAAEmB,CAAC,EAAE,EAAE;IACzC+B,gBAAgB,CAAC/B,CAAC,CAAC,GAAG,EAAE;IACxB,KAAK,IAAIqC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGR,SAAS,CAAChD,MAAM,EAAEwD,CAAC,EAAE,EAAE;MACzCN,gBAAgB,CAAC/B,CAAC,CAAC,CAACqC,CAAC,CAAC,GAAGrC,CAAC,KAAKqC,CAAC,GAAG,CAAC,GAAGvD,gBAAgB,CAAC+C,SAAS,CAAC7B,CAAC,CAAC,EAAE6B,SAAS,CAACQ,CAAC,CAAC,CAAC;IACrF;EACF;;EAEA;EACA,MAAMyC,iBAAiB,GAAGlD,yBAAyB,CAACC,SAAS,EAAEmE,cAAc,EAAEjE,gBAAgB,CAAC;EAEhG,OAAO;IACLgD,MAAM,EAAE,iBAAiB;IACzBJ,OAAO;IACP9C,SAAS,EAAEpB,iBAAiB;IAC5BuE,cAAc,EAAEP,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS;IACtCK,cAAc;IACdC;EACF,CAAC;AACH","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}